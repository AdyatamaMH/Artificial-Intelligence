{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f301c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f962fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Depo Plumpang Terbakar, Anggota DPR Minta Pert...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698528/depo-pl...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "      <td>[-0.01590039,-0.034130897,0.005732614,-0.01853...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Anggota Komisi VII DPR RI Rofik Hananto menyay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698522/jokowi-...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "      <td>[-0.017608976,-0.021786924,0.01547983,-0.00932...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Presiden Joko Widodo telah memerintahkan Wakil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>tempo</td>\n",
       "      <td>HNW Mendukung Jamaah Umroh First Travel Dapatk...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698527/hnw-men...</td>\n",
       "      <td>INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "      <td>[0.00841488,-0.023665192,0.006762431,-0.013723...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698540/tim-dok...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "      <td>[-0.012671886,-0.0039057182,0.019575326,-0.016...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Tim Kedokteran dan Kesehatan (Dokkes) Polri te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Bamsoet Ajak Komunitas Otomotif Kembangkan Per...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698536/bamsoet...</td>\n",
       "      <td>INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "      <td>[-0.015486176,-0.0125719,-0.0122843925,-0.0343...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Ketua MPR RI Bambang Soesatyo telah diangkat s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id source                                              title  \\\n",
       "0  83  tempo  Depo Plumpang Terbakar, Anggota DPR Minta Pert...   \n",
       "1  84  tempo  Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...   \n",
       "2  85  tempo  HNW Mendukung Jamaah Umroh First Travel Dapatk...   \n",
       "3  86  tempo  Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...   \n",
       "4  87  tempo  Bamsoet Ajak Komunitas Otomotif Kembangkan Per...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "1  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "2  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "3  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "4  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://nasional.tempo.co/read/1698528/depo-pl...   \n",
       "1  https://nasional.tempo.co/read/1698522/jokowi-...   \n",
       "2  https://nasional.tempo.co/read/1698527/hnw-men...   \n",
       "3  https://nasional.tempo.co/read/1698540/tim-dok...   \n",
       "4  https://nasional.tempo.co/read/1698536/bamsoet...   \n",
       "\n",
       "                                             content                    date  \\\n",
       "0  TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...  2023-03-04 06:18:13+00   \n",
       "1  TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...  2023-03-04 06:04:38+00   \n",
       "2  INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...  2023-03-04 06:18:04+00   \n",
       "3  TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...  2023-03-04 06:44:10+00   \n",
       "4  INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...  2023-03-04 06:38:57+00   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.01590039,-0.034130897,0.005732614,-0.01853...   \n",
       "1  [-0.017608976,-0.021786924,0.01547983,-0.00932...   \n",
       "2  [0.00841488,-0.023665192,0.006762431,-0.013723...   \n",
       "3  [-0.012671886,-0.0039057182,0.019575326,-0.016...   \n",
       "4  [-0.015486176,-0.0125719,-0.0122843925,-0.0343...   \n",
       "\n",
       "                   created_at                  updated_at  \\\n",
       "0  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "1  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "2  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "3  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "4  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "\n",
       "                                             summary  \n",
       "0  Anggota Komisi VII DPR RI Rofik Hananto menyay...  \n",
       "1  Presiden Joko Widodo telah memerintahkan Wakil...  \n",
       "2  Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...  \n",
       "3  Tim Kedokteran dan Kesehatan (Dokkes) Polri te...  \n",
       "4  Ketua MPR RI Bambang Soesatyo telah diangkat s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Initial Data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f6b7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>nama file gambar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>71.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>17-Jul-20</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>461.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>13-Jul-20</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>495.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>8-Jul-20</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>550.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>24-Jun-20</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>681.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  label    tanggal                                              judul  \\\n",
       "0   71      1  17-Aug-20  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  461      1  17-Jul-20  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  495      1  13-Jul-20  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  550      1   8-Jul-20  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4  681      1  24-Jun-20       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "\n",
       "                                              narasi nama file gambar  \n",
       "0  A caller to a radio talk show recently shared ...           71.jpg  \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...          461.png  \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...          495.png  \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...          550.png  \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .          681.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'Data_latih.csv'\n",
    "df2 = pd.read_csv(file_path)\n",
    "print(\"Initial Data:\")\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd87d9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>label</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>nama file gambar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "      <td>71.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "      <td>17-Jul-20</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "      <td>461.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>13-Jul-20</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "      <td>495.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>8-Jul-20</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "      <td>550.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>24-Jun-20</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "      <td>681.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  label publication_date  \\\n",
       "0         71      1        17-Aug-20   \n",
       "1        461      1        17-Jul-20   \n",
       "2        495      1        13-Jul-20   \n",
       "3        550      1         8-Jul-20   \n",
       "4        681      1        24-Jun-20   \n",
       "\n",
       "                                               title  \\\n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "\n",
       "                                             content nama file gambar  \n",
       "0  A caller to a radio talk show recently shared ...           71.jpg  \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...          461.png  \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...          495.png  \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...          550.png  \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .          681.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df2.rename(columns={\n",
    "    'ID': 'record_id',\n",
    "    'judul': 'title',\n",
    "    'narasi': 'content',\n",
    "    'tanggal': 'publication_date'\n",
    "})\n",
    "\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c557a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>Pemakaian Masker Menyebabkan Penyakit Legionna...</td>\n",
       "      <td>A caller to a radio talk show recently shared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>17-Jul-20</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>13-Jul-20</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>8-Jul-20</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681</td>\n",
       "      <td>24-Jun-20</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id publication_date  \\\n",
       "0         71        17-Aug-20   \n",
       "1        461        17-Jul-20   \n",
       "2        495        13-Jul-20   \n",
       "3        550         8-Jul-20   \n",
       "4        681        24-Jun-20   \n",
       "\n",
       "                                               title  \\\n",
       "0  Pemakaian Masker Menyebabkan Penyakit Legionna...   \n",
       "1  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "2  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "3  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "4       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "\n",
       "                                             content  \n",
       "0  A caller to a radio talk show recently shared ...  \n",
       "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...  \n",
       "2  Jokowi adalah presiden terbaik dlm sejarah ban...  \n",
       "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...  \n",
       "4        Kadrun kalo lihat foto ini panas dingin . .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df2.drop(columns=['nama file gambar', 'label'])\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f987c8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>17-Jul-20</td>\n",
       "      <td>Instruksi Gubernur Jateng tentang penilangan  ...</td>\n",
       "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495</td>\n",
       "      <td>13-Jul-20</td>\n",
       "      <td>Foto Jim Rohn: Jokowi adalah presiden terbaik ...</td>\n",
       "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550</td>\n",
       "      <td>8-Jul-20</td>\n",
       "      <td>ini bukan politik, tapi kenyataan Pak Jokowi b...</td>\n",
       "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681</td>\n",
       "      <td>24-Jun-20</td>\n",
       "      <td>Foto Kadrun kalo lihat foto ini panas dingin</td>\n",
       "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736</td>\n",
       "      <td>17-Jun-20</td>\n",
       "      <td>event promo smartphone JNE 2020 spesial di bul...</td>\n",
       "      <td>selamat siang teman teman fb ku semuanya🤩,cuma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id publication_date  \\\n",
       "0        461        17-Jul-20   \n",
       "1        495        13-Jul-20   \n",
       "2        550         8-Jul-20   \n",
       "3        681        24-Jun-20   \n",
       "4        736        17-Jun-20   \n",
       "\n",
       "                                               title  \\\n",
       "0  Instruksi Gubernur Jateng tentang penilangan  ...   \n",
       "1  Foto Jim Rohn: Jokowi adalah presiden terbaik ...   \n",
       "2  ini bukan politik, tapi kenyataan Pak Jokowi b...   \n",
       "3       Foto Kadrun kalo lihat foto ini panas dingin   \n",
       "4  event promo smartphone JNE 2020 spesial di bul...   \n",
       "\n",
       "                                             content  \n",
       "0  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...  \n",
       "1  Jokowi adalah presiden terbaik dlm sejarah ban...  \n",
       "2  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...  \n",
       "3        Kadrun kalo lihat foto ini panas dingin . .  \n",
       "4  selamat siang teman teman fb ku semuanya🤩,cuma...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df2.iloc[1:].reset_index(drop=True)\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cc2227d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['image', 'url', 'embedding', 'created_at', 'updated_at', 'summary', 'source'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_at\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAfter Dropping Unnecessary Columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5210\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['image', 'url', 'embedding', 'created_at', 'updated_at', 'summary', 'source'] not found in axis\""
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['image', 'url', 'embedding', 'created_at', 'updated_at','summary','source']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(\"\\nAfter Dropping Unnecessary Columns:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6faa0e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Renaming Columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>depo plumpang terbakar, anggota dpr minta pert...</td>\n",
       "      <td>tempo.co, jakarta - anggota komisi 7 dpr ri ro...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>jokowi perintahkan wapres ma'ruf amin tinjau l...</td>\n",
       "      <td>tempo.co, jakarta - presiden joko widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>hnw mendukung jamaah umroh first travel dapatk...</td>\n",
       "      <td>info nasional - wakil ketua mpr ri dr. h. m. h...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>tim dokkes polri telah terima 14 kantong jenaz...</td>\n",
       "      <td>tempo.co, jakarta - tim kedokteran dan kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>bamsoet ajak komunitas otomotif kembangkan per...</td>\n",
       "      <td>info nasional - ketua mpr ri sekaligus ketua u...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id                                              title  \\\n",
       "0         83  depo plumpang terbakar, anggota dpr minta pert...   \n",
       "1         84  jokowi perintahkan wapres ma'ruf amin tinjau l...   \n",
       "2         85  hnw mendukung jamaah umroh first travel dapatk...   \n",
       "3         86  tim dokkes polri telah terima 14 kantong jenaz...   \n",
       "4         87  bamsoet ajak komunitas otomotif kembangkan per...   \n",
       "\n",
       "                                             content        publication_date  \\\n",
       "0  tempo.co, jakarta - anggota komisi 7 dpr ri ro...  2023-03-04 06:18:13+00   \n",
       "1  tempo.co, jakarta - presiden joko widodo atau ...  2023-03-04 06:04:38+00   \n",
       "2  info nasional - wakil ketua mpr ri dr. h. m. h...  2023-03-04 06:18:04+00   \n",
       "3  tempo.co, jakarta - tim kedokteran dan kesehat...  2023-03-04 06:44:10+00   \n",
       "4  info nasional - ketua mpr ri sekaligus ketua u...  2023-03-04 06:38:57+00   \n",
       "\n",
       "   status  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_rename_map = {\n",
    "    'id': 'record_id',\n",
    "    'source': 'news_source',\n",
    "    'date': 'publication_date'\n",
    "}\n",
    "df.rename(columns=columns_rename_map, inplace=True)\n",
    "print(\"\\nAfter Renaming Columns:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267097a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>Depo Plumpang Terbakar, Anggota DPR Minta Pert...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>HNW Mendukung Jamaah Umroh First Travel Dapatk...</td>\n",
       "      <td>INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>Bamsoet Ajak Komunitas Otomotif Kembangkan Per...</td>\n",
       "      <td>INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id                                              title  \\\n",
       "0         83  Depo Plumpang Terbakar, Anggota DPR Minta Pert...   \n",
       "1         84  Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...   \n",
       "2         85  HNW Mendukung Jamaah Umroh First Travel Dapatk...   \n",
       "3         86  Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...   \n",
       "4         87  Bamsoet Ajak Komunitas Otomotif Kembangkan Per...   \n",
       "\n",
       "                                             content        publication_date  \n",
       "0  TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...  2023-03-04 06:18:13+00  \n",
       "1  TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...  2023-03-04 06:04:38+00  \n",
       "2  INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...  2023-03-04 06:18:04+00  \n",
       "3  TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...  2023-03-04 06:44:10+00  \n",
       "4  INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...  2023-03-04 06:38:57+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c8a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>depo plumpang terbakar, anggota dpr minta pert...</td>\n",
       "      <td>tempo.co, jakarta - anggota komisi 7 dpr ri ro...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>jokowi perintahkan wapres ma'ruf amin tinjau l...</td>\n",
       "      <td>tempo.co, jakarta - presiden joko widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>hnw mendukung jamaah umroh first travel dapatk...</td>\n",
       "      <td>info nasional - wakil ketua mpr ri dr. h. m. h...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>tim dokkes polri telah terima 14 kantong jenaz...</td>\n",
       "      <td>tempo.co, jakarta - tim kedokteran dan kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>bamsoet ajak komunitas otomotif kembangkan per...</td>\n",
       "      <td>info nasional - ketua mpr ri sekaligus ketua u...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0  83  depo plumpang terbakar, anggota dpr minta pert...   \n",
       "1  84  jokowi perintahkan wapres ma'ruf amin tinjau l...   \n",
       "2  85  hnw mendukung jamaah umroh first travel dapatk...   \n",
       "3  86  tim dokkes polri telah terima 14 kantong jenaz...   \n",
       "4  87  bamsoet ajak komunitas otomotif kembangkan per...   \n",
       "\n",
       "                                             content                    date  \n",
       "0  tempo.co, jakarta - anggota komisi 7 dpr ri ro...  2023-03-04 06:18:13+00  \n",
       "1  tempo.co, jakarta - presiden joko widodo atau ...  2023-03-04 06:04:38+00  \n",
       "2  info nasional - wakil ketua mpr ri dr. h. m. h...  2023-03-04 06:18:04+00  \n",
       "3  tempo.co, jakarta - tim kedokteran dan kesehat...  2023-03-04 06:44:10+00  \n",
       "4  info nasional - ketua mpr ri sekaligus ketua u...  2023-03-04 06:38:57+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roman_to_int(roman):\n",
    "    roman_map = {\n",
    "        'I': 1, 'II': 2, 'III': 3, 'IV': 4, \n",
    "        'V': 5, 'VI': 6, 'VII': 7, 'VIII': 8, \n",
    "        'IX': 9, 'X': 10\n",
    "    }\n",
    "\n",
    "    return roman_map.get(roman, roman)\n",
    "\n",
    "\n",
    "def convert_roman_to_int(text):\n",
    "    def replace_roman(match):\n",
    "        roman_numeral = match.group(0)\n",
    "        return str(roman_to_int(roman_numeral))  # Convert Roman numeral to integer\n",
    "    \n",
    "\n",
    "    return re.sub(r'\\b(I|II|III|IV|V|VI|VII|VIII|IX|X)\\b', replace_roman, text)\n",
    "\n",
    "\n",
    "for col in ['title', 'content']:\n",
    "    df[col] = df[col].apply(lambda x: convert_roman_to_int(x) if isinstance(x, str) else x)\n",
    "    df[col] = df[col].str.lower()  # Convert to lowercase\n",
    "\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b27ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>999287</td>\n",
       "      <td>17-Jan-16</td>\n",
       "      <td>: kpk dilarang membawa brimob bersenjata masuk...</td>\n",
       "      <td>kpk dilarang membawa brimob bersenjata masuk g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>999472</td>\n",
       "      <td>20-Aug-20</td>\n",
       "      <td>foto pejabat keuangan dibawah palu arit</td>\n",
       "      <td>jangan mau dialihkan kepada pakaian adat… foku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>999501</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>gambar denny siregar musuh warga tasikmalaya d...</td>\n",
       "      <td>akhir nya bisa terkenal bang denny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>999848</td>\n",
       "      <td>21-Jul-20</td>\n",
       "      <td>kaesang: bapak saya dengan kesederhaan bisa ni...</td>\n",
       "      <td>bapak saya dengan kesederhaan bisa nipu rakyat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>999860</td>\n",
       "      <td>20-Jul-20</td>\n",
       "      <td>laser dari termometer gun akan merusak struktu...</td>\n",
       "      <td>in: saya nolak. kalau anda mau periksa, bukan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      record_id publication_date  \\\n",
       "4225     999287        17-Jan-16   \n",
       "4226     999472        20-Aug-20   \n",
       "4227     999501        17-Aug-20   \n",
       "4228     999848        21-Jul-20   \n",
       "4229     999860        20-Jul-20   \n",
       "\n",
       "                                                  title  \\\n",
       "4225  : kpk dilarang membawa brimob bersenjata masuk...   \n",
       "4226            foto pejabat keuangan dibawah palu arit   \n",
       "4227  gambar denny siregar musuh warga tasikmalaya d...   \n",
       "4228  kaesang: bapak saya dengan kesederhaan bisa ni...   \n",
       "4229  laser dari termometer gun akan merusak struktu...   \n",
       "\n",
       "                                                content  \n",
       "4225  kpk dilarang membawa brimob bersenjata masuk g...  \n",
       "4226  jangan mau dialihkan kepada pakaian adat… foku...  \n",
       "4227                 akhir nya bisa terkenal bang denny  \n",
       "4228  bapak saya dengan kesederhaan bisa nipu rakyat...  \n",
       "4229  in: saya nolak. kalau anda mau periksa, bukan ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roman_to_int(roman):\n",
    "    roman_map = {\n",
    "        'I': 1, 'II': 2, 'III': 3, 'IV': 4, \n",
    "        'V': 5, 'VI': 6, 'VII': 7, 'VIII': 8, \n",
    "        'IX': 9, 'X': 10\n",
    "    }\n",
    "\n",
    "    return roman_map.get(roman, roman)\n",
    "\n",
    "\n",
    "def convert_roman_to_int(text):\n",
    "    def replace_roman(match):\n",
    "        roman_numeral = match.group(0)\n",
    "        return str(roman_to_int(roman_numeral))  # Convert Roman numeral to integer\n",
    "    \n",
    "\n",
    "    return re.sub(r'\\b(I|II|III|IV|V|VI|VII|VIII|IX|X)\\b', replace_roman, text)\n",
    "\n",
    "\n",
    "for col in ['title', 'content']:\n",
    "    df2[col] = df2[col].apply(lambda x: convert_roman_to_int(x) if isinstance(x, str) else x)\n",
    "    df2[col] = df2[col].str.lower()  # Convert to lowercase\n",
    "\n",
    "\n",
    "display(df2.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73fa3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              title  \\\n",
      "0         83  depo plumpang terbakar, anggota dpr minta pert...   \n",
      "1         84  jokowi perintahkan wapres ma'ruf amin tinjau l...   \n",
      "2         85  hnw mendukung jamaah umroh first travel dapatk...   \n",
      "3         86  tim dokkes polri telah terima 14 kantong jenaz...   \n",
      "4         87  bamsoet ajak komunitas otomotif kembangkan per...   \n",
      "...      ...                                                ...   \n",
      "32730  63563  5 hewan aneh yang hidup di palung mariana, sal...   \n",
      "32731  63564  biadab! guru sd di banyuwangi cabuli siswinya,...   \n",
      "32732  63565  aji santoso: jakmania perlakukan persebaya den...   \n",
      "32733  63566  sopir audi cium kaki ibu & istri hamil usai si...   \n",
      "32734  63567          ini besaran biaya haji 2023 per embarkasi   \n",
      "\n",
      "                                                 content  \\\n",
      "0      tempo.co, jakarta - anggota komisi 7 dpr ri ro...   \n",
      "1      tempo.co, jakarta - presiden joko widodo atau ...   \n",
      "2      info nasional - wakil ketua mpr ri dr. h. m. h...   \n",
      "3      tempo.co, jakarta - tim kedokteran dan kesehat...   \n",
      "4      info nasional - ketua mpr ri sekaligus ketua u...   \n",
      "...                                                  ...   \n",
      "32730  menjadi salah satu lubang terdalam dan tergela...   \n",
      "32731  seorang guru sd di banyuwangi ditangkap oleh p...   \n",
      "32732  pelatih , aji santoso, salut dengan sambutan s...   \n",
      "32733  suasana haru terjadi usai sidang terdakwa suge...   \n",
      "32734  tempo.co, jakarta - presiden joko widodo telah...   \n",
      "\n",
      "                         date  status  \n",
      "0      2023-03-04 06:18:13+00       1  \n",
      "1      2023-03-04 06:04:38+00       1  \n",
      "2      2023-03-04 06:18:04+00       1  \n",
      "3      2023-03-04 06:44:10+00       1  \n",
      "4      2023-03-04 06:38:57+00       1  \n",
      "...                       ...     ...  \n",
      "32730  2023-04-11 20:13:25+00       1  \n",
      "32731  2023-04-11 20:05:30+00       1  \n",
      "32732  2023-04-11 19:37:49+00       1  \n",
      "32733  2023-04-11 19:24:07+00       1  \n",
      "32734  2023-04-11 20:00:00+00       1  \n",
      "\n",
      "[32735 rows x 5 columns]\n",
      "      record_id publication_date  \\\n",
      "0           461        17-Jul-20   \n",
      "1           495        13-Jul-20   \n",
      "2           550         8-Jul-20   \n",
      "3           681        24-Jun-20   \n",
      "4           736        17-Jun-20   \n",
      "...         ...              ...   \n",
      "4225     999287        17-Jan-16   \n",
      "4226     999472        20-Aug-20   \n",
      "4227     999501        17-Aug-20   \n",
      "4228     999848        21-Jul-20   \n",
      "4229     999860        20-Jul-20   \n",
      "\n",
      "                                                  title  \\\n",
      "0     instruksi gubernur jateng tentang penilangan  ...   \n",
      "1     foto jim rohn: jokowi adalah presiden terbaik ...   \n",
      "2     ini bukan politik, tapi kenyataan pak jokowi b...   \n",
      "3          foto kadrun kalo lihat foto ini panas dingin   \n",
      "4     event promo smartphone jne 2020 spesial di bul...   \n",
      "...                                                 ...   \n",
      "4225  : kpk dilarang membawa brimob bersenjata masuk...   \n",
      "4226            foto pejabat keuangan dibawah palu arit   \n",
      "4227  gambar denny siregar musuh warga tasikmalaya d...   \n",
      "4228  kaesang: bapak saya dengan kesederhaan bisa ni...   \n",
      "4229  laser dari termometer gun akan merusak struktu...   \n",
      "\n",
      "                                                content  status  \n",
      "0     yth.seluruh anggota grup sesuai instruksi gube...       0  \n",
      "1     jokowi adalah presiden terbaik dlm sejarah ban...       0  \n",
      "2     maaf mas2 dan mbak2, ini bukan politik, tapi k...       0  \n",
      "3           kadrun kalo lihat foto ini panas dingin . .       0  \n",
      "4     selamat siang teman teman fb ku semuanya🤩,cuma...       0  \n",
      "...                                                 ...     ...  \n",
      "4225  kpk dilarang membawa brimob bersenjata masuk g...       0  \n",
      "4226  jangan mau dialihkan kepada pakaian adat… foku...       0  \n",
      "4227                 akhir nya bisa terkenal bang denny       0  \n",
      "4228  bapak saya dengan kesederhaan bisa nipu rakyat...       0  \n",
      "4229  in: saya nolak. kalau anda mau periksa, bukan ...       0  \n",
      "\n",
      "[4230 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['status'] = 1\n",
    "df2['status'] = 0\n",
    "print(df)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a148ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>999287</td>\n",
       "      <td>: kpk dilarang membawa brimob bersenjata masuk...</td>\n",
       "      <td>kpk dilarang membawa brimob bersenjata masuk g...</td>\n",
       "      <td>17-Jan-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>999472</td>\n",
       "      <td>foto pejabat keuangan dibawah palu arit</td>\n",
       "      <td>jangan mau dialihkan kepada pakaian adat… foku...</td>\n",
       "      <td>20-Aug-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>999501</td>\n",
       "      <td>gambar denny siregar musuh warga tasikmalaya d...</td>\n",
       "      <td>akhir nya bisa terkenal bang denny</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>999848</td>\n",
       "      <td>kaesang: bapak saya dengan kesederhaan bisa ni...</td>\n",
       "      <td>bapak saya dengan kesederhaan bisa nipu rakyat...</td>\n",
       "      <td>21-Jul-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36964</th>\n",
       "      <td>999860</td>\n",
       "      <td>laser dari termometer gun akan merusak struktu...</td>\n",
       "      <td>in: saya nolak. kalau anda mau periksa, bukan ...</td>\n",
       "      <td>20-Jul-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_id                                              title  \\\n",
       "36960     999287  : kpk dilarang membawa brimob bersenjata masuk...   \n",
       "36961     999472            foto pejabat keuangan dibawah palu arit   \n",
       "36962     999501  gambar denny siregar musuh warga tasikmalaya d...   \n",
       "36963     999848  kaesang: bapak saya dengan kesederhaan bisa ni...   \n",
       "36964     999860  laser dari termometer gun akan merusak struktu...   \n",
       "\n",
       "                                                 content publication_date  \\\n",
       "36960  kpk dilarang membawa brimob bersenjata masuk g...        17-Jan-16   \n",
       "36961  jangan mau dialihkan kepada pakaian adat… foku...        20-Aug-20   \n",
       "36962                 akhir nya bisa terkenal bang denny        17-Aug-20   \n",
       "36963  bapak saya dengan kesederhaan bisa nipu rakyat...        21-Jul-20   \n",
       "36964  in: saya nolak. kalau anda mau periksa, bukan ...        20-Jul-20   \n",
       "\n",
       "       status  \n",
       "36960       0  \n",
       "36961       0  \n",
       "36962       0  \n",
       "36963       0  \n",
       "36964       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.merge(df, df2, on=['record_id', 'content','status','title','publication_date'], how='outer')\n",
    "df_merge.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d69b664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_merge = df_merge.dropna()\n",
    "print(df_merge.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c846f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to cleaned_merge_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>999287</td>\n",
       "      <td>: kpk dilarang membawa brimob bersenjata masuk...</td>\n",
       "      <td>kpk dilarang membawa brimob bersenjata masuk g...</td>\n",
       "      <td>17-Jan-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>999472</td>\n",
       "      <td>foto pejabat keuangan dibawah palu arit</td>\n",
       "      <td>jangan mau dialihkan kepada pakaian adat… foku...</td>\n",
       "      <td>20-Aug-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>999501</td>\n",
       "      <td>gambar denny siregar musuh warga tasikmalaya d...</td>\n",
       "      <td>akhir nya bisa terkenal bang denny</td>\n",
       "      <td>17-Aug-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>999848</td>\n",
       "      <td>kaesang: bapak saya dengan kesederhaan bisa ni...</td>\n",
       "      <td>bapak saya dengan kesederhaan bisa nipu rakyat...</td>\n",
       "      <td>21-Jul-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36964</th>\n",
       "      <td>999860</td>\n",
       "      <td>laser dari termometer gun akan merusak struktu...</td>\n",
       "      <td>in: saya nolak. kalau anda mau periksa, bukan ...</td>\n",
       "      <td>20-Jul-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_id                                              title  \\\n",
       "36960     999287  : kpk dilarang membawa brimob bersenjata masuk...   \n",
       "36961     999472            foto pejabat keuangan dibawah palu arit   \n",
       "36962     999501  gambar denny siregar musuh warga tasikmalaya d...   \n",
       "36963     999848  kaesang: bapak saya dengan kesederhaan bisa ni...   \n",
       "36964     999860  laser dari termometer gun akan merusak struktu...   \n",
       "\n",
       "                                                 content publication_date  \\\n",
       "36960  kpk dilarang membawa brimob bersenjata masuk g...        17-Jan-16   \n",
       "36961  jangan mau dialihkan kepada pakaian adat… foku...        20-Aug-20   \n",
       "36962                 akhir nya bisa terkenal bang denny        17-Aug-20   \n",
       "36963  bapak saya dengan kesederhaan bisa nipu rakyat...        21-Jul-20   \n",
       "36964  in: saya nolak. kalau anda mau periksa, bukan ...        20-Jul-20   \n",
       "\n",
       "       status  \n",
       "36960       0  \n",
       "36961       0  \n",
       "36962       0  \n",
       "36963       0  \n",
       "36964       0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_file_path = 'cleaned_merge_data.csv'\n",
    "df_merge.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned data saved to {cleaned_file_path}\")\n",
    "df_merge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c97a18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_merge.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e15ae402",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [38], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallenai/longformer-base-4096\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns_to_tokenize:\n\u001b[1;32m----> 9\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_token_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tokenizer\u001b[38;5;241m.\u001b[39mencode(x, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     16\u001b[0m tokenized_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4765\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1286\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1292\u001b[0m     )  \u001b[38;5;66;03m# GH52116\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1810\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1815\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1816\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn [38], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallenai/longformer-base-4096\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns_to_tokenize:\n\u001b[0;32m      9\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_token_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[column]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tokenizer\u001b[38;5;241m.\u001b[39mencode(x, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     16\u001b[0m tokenized_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:411\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.tokenize\u001b[1;34m(self, text, pair, add_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, pair: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, add_special_tokens: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mpair, add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mtokens()\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3207\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3197\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3198\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3199\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3200\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3204\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3205\u001b[0m )\n\u001b[1;32m-> 3207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   3208\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3209\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   3210\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3211\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3212\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3213\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3214\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3215\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3216\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3217\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   3218\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3219\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3220\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3221\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3222\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3223\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3224\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3225\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3226\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_special_tokens),\n\u001b[0;32m   3227\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3228\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\longformer\\tokenization_longformer_fast.py:236\u001b[0m, in \u001b[0;36mLongformerTokenizerFast._encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m )\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:603\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    581\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    601\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m    602\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[1;32m--> 603\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    604\u001b[0m         batched_input,\n\u001b[0;32m    605\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m    606\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    607\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    608\u001b[0m         truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    609\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    610\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m    611\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    612\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m    613\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    614\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    615\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    616\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    617\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    618\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    619\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    620\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    621\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m    622\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    623\u001b[0m     )\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\longformer\\tokenization_longformer_fast.py:226\u001b[0m, in \u001b[0;36mLongformerTokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m )\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:529\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[1;32m--> 529\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    541\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    543\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    553\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_file_path = 'cleaned_merge_data.csv'\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "columns_to_tokenize = ['title', 'content']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "for column in columns_to_tokenize:\n",
    "    df[f\"{column}_tokens\"] = df[column].apply(\n",
    "        lambda x: tokenizer.tokenize(x) if pd.notnull(x) else []\n",
    "    )\n",
    "    df[f\"{column}_token_ids\"] = df[column].apply(\n",
    "        lambda x: tokenizer.encode(x, truncation=True, max_length=512) if pd.notnull(x) else []\n",
    "    )\n",
    "\n",
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df.to_csv(tokenized_file_path, index=False)\n",
    "print(f\"Tokenized data saved to {tokenized_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a726a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbc25f260e14e92812b44f2a795f407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raja\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1912b79cb1cf4ecd96222e3387eb6fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d7c3747d4448be9f376ed75dc55084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f257f356a14d30993f425d440fbd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized data saved to tokenized_data.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = 'cleaned_merge_data.csv'\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# Columns to tokenize\n",
    "columns_to_tokenize = ['title', 'content']\n",
    "\n",
    "# Load IndoBERT tokenizer (IndoBERT is based on BERT, but fine-tuned for Indonesian)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Tokenize and encode the columns\n",
    "for column in columns_to_tokenize:\n",
    "    # Tokenize the text (splitting into subword tokens)\n",
    "    df[f\"{column}_tokens\"] = df[column].apply(\n",
    "        lambda x: tokenizer.tokenize(x) if pd.notnull(x) else []\n",
    "    )\n",
    "    \n",
    "    # Encode the text into token IDs (including truncation and padding)\n",
    "    df[f\"{column}_token_ids\"] = df[column].apply(\n",
    "        lambda x: tokenizer.encode(x, truncation=True, max_length=512) if pd.notnull(x) else []\n",
    "    )\n",
    "\n",
    "# Save the tokenized data to a new CSV file\n",
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df.to_csv(tokenized_file_path, index=False)\n",
    "\n",
    "# Output message\n",
    "print(f\"Tokenized data saved to {tokenized_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19bf13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = 'cleaned_merge_data.csv'\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "columns_to_tokenize = ['title', 'content']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "for column in columns_to_tokenize:\n",
    "    df[f\"{column}_tokens\"] = df[column].apply(\n",
    "        lambda x: tokenizer.tokenize(x) if pd.notnull(x) else []\n",
    "    )\n",
    "    \n",
    "    df[f\"{column}_token_ids\"] = df[column].apply(\n",
    "        lambda x: tokenizer.encode(x, truncation=True, max_length=512) if pd.notnull(x) else []\n",
    "    )\n",
    "\n",
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df.to_csv(tokenized_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e127fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>status</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_token_ids</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>depo plumpang terbakar, anggota dpr minta pert...</td>\n",
       "      <td>tempo.co, jakarta - anggota komisi 7 dpr ri ro...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁de, po, ▁plu, mpang, ▁terbakar, ,, ▁anggota,...</td>\n",
       "      <td>[0, 8, 771, 12266, 58098, 215404, 4, 26881, 10...</td>\n",
       "      <td>[▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁anggota, ▁...</td>\n",
       "      <td>[0, 2167, 5, 587, 4, 79, 59505, 20, 26881, 602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>jokowi perintahkan wapres ma'ruf amin tinjau l...</td>\n",
       "      <td>tempo.co, jakarta - presiden joko widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁jo, kowi, ▁perintah, kan, ▁wa, pres, ▁ma, ',...</td>\n",
       "      <td>[0, 741, 62248, 95447, 331, 259, 9518, 291, 25...</td>\n",
       "      <td>[▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁presiden, ...</td>\n",
       "      <td>[0, 2167, 5, 587, 4, 79, 59505, 20, 79390, 625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>hnw mendukung jamaah umroh first travel dapatk...</td>\n",
       "      <td>info nasional - wakil ketua mpr ri dr. h. m. h...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁h, n, w, ▁mendukung, ▁ja, ma, ah, ▁um, roh, ...</td>\n",
       "      <td>[0, 1096, 19, 434, 80279, 79, 192, 1366, 286, ...</td>\n",
       "      <td>[▁info, ▁nasional, ▁-, ▁wakil, ▁ketua, ▁mp, r,...</td>\n",
       "      <td>[0, 3004, 47951, 20, 81724, 90558, 9607, 42, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>tim dokkes polri telah terima 14 kantong jenaz...</td>\n",
       "      <td>tempo.co, jakarta - tim kedokteran dan kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁tim, ▁dok, kes, ▁pol, ri, ▁telah, ▁terima, ▁...</td>\n",
       "      <td>[0, 5527, 11081, 9248, 3722, 416, 1825, 38119,...</td>\n",
       "      <td>[▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁tim, ▁ke, ...</td>\n",
       "      <td>[0, 2167, 5, 587, 4, 79, 59505, 20, 5527, 311,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>bamsoet ajak komunitas otomotif kembangkan per...</td>\n",
       "      <td>info nasional - ketua mpr ri sekaligus ketua u...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "      <td>1</td>\n",
       "      <td>[▁bam, so, et, ▁a, jak, ▁komunitas, ▁oto, moti...</td>\n",
       "      <td>[0, 81020, 991, 126, 10, 9860, 152718, 21668, ...</td>\n",
       "      <td>[▁info, ▁nasional, ▁-, ▁ketua, ▁mp, r, ▁ri, ▁s...</td>\n",
       "      <td>[0, 3004, 47951, 20, 90558, 9607, 42, 1427, 70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id                                              title  \\\n",
       "0         83  depo plumpang terbakar, anggota dpr minta pert...   \n",
       "1         84  jokowi perintahkan wapres ma'ruf amin tinjau l...   \n",
       "2         85  hnw mendukung jamaah umroh first travel dapatk...   \n",
       "3         86  tim dokkes polri telah terima 14 kantong jenaz...   \n",
       "4         87  bamsoet ajak komunitas otomotif kembangkan per...   \n",
       "\n",
       "                                             content        publication_date  \\\n",
       "0  tempo.co, jakarta - anggota komisi 7 dpr ri ro...  2023-03-04 06:18:13+00   \n",
       "1  tempo.co, jakarta - presiden joko widodo atau ...  2023-03-04 06:04:38+00   \n",
       "2  info nasional - wakil ketua mpr ri dr. h. m. h...  2023-03-04 06:18:04+00   \n",
       "3  tempo.co, jakarta - tim kedokteran dan kesehat...  2023-03-04 06:44:10+00   \n",
       "4  info nasional - ketua mpr ri sekaligus ketua u...  2023-03-04 06:38:57+00   \n",
       "\n",
       "   status                                       title_tokens  \\\n",
       "0       1  [▁de, po, ▁plu, mpang, ▁terbakar, ,, ▁anggota,...   \n",
       "1       1  [▁jo, kowi, ▁perintah, kan, ▁wa, pres, ▁ma, ',...   \n",
       "2       1  [▁h, n, w, ▁mendukung, ▁ja, ma, ah, ▁um, roh, ...   \n",
       "3       1  [▁tim, ▁dok, kes, ▁pol, ri, ▁telah, ▁terima, ▁...   \n",
       "4       1  [▁bam, so, et, ▁a, jak, ▁komunitas, ▁oto, moti...   \n",
       "\n",
       "                                     title_token_ids  \\\n",
       "0  [0, 8, 771, 12266, 58098, 215404, 4, 26881, 10...   \n",
       "1  [0, 741, 62248, 95447, 331, 259, 9518, 291, 25...   \n",
       "2  [0, 1096, 19, 434, 80279, 79, 192, 1366, 286, ...   \n",
       "3  [0, 5527, 11081, 9248, 3722, 416, 1825, 38119,...   \n",
       "4  [0, 81020, 991, 126, 10, 9860, 152718, 21668, ...   \n",
       "\n",
       "                                      content_tokens  \\\n",
       "0  [▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁anggota, ▁...   \n",
       "1  [▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁presiden, ...   \n",
       "2  [▁info, ▁nasional, ▁-, ▁wakil, ▁ketua, ▁mp, r,...   \n",
       "3  [▁tempo, ., co, ,, ▁ja, karta, ▁-, ▁tim, ▁ke, ...   \n",
       "4  [▁info, ▁nasional, ▁-, ▁ketua, ▁mp, r, ▁ri, ▁s...   \n",
       "\n",
       "                                   content_token_ids  \n",
       "0  [0, 2167, 5, 587, 4, 79, 59505, 20, 26881, 602...  \n",
       "1  [0, 2167, 5, 587, 4, 79, 59505, 20, 79390, 625...  \n",
       "2  [0, 3004, 47951, 20, 81724, 90558, 9607, 42, 1...  \n",
       "3  [0, 2167, 5, 587, 4, 79, 59505, 20, 5527, 311,...  \n",
       "4  [0, 3004, 47951, 20, 90558, 9607, 42, 1427, 70...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df.to_csv(tokenized_file_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3c6c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reconstruction accuracy: 81.19%\n"
     ]
    }
   ],
   "source": [
    "def reconstruction_accuracy(df, columns_to_tokenize, tokenizer):\n",
    "    matches = 0\n",
    "    total = 0\n",
    "\n",
    "    for column in columns_to_tokenize:\n",
    "        for text in df[column]:\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            \n",
    "            reconstructed = tokenizer.convert_tokens_to_string(tokens)\n",
    "            \n",
    "            if text == reconstructed:\n",
    "                matches += 1\n",
    "            \n",
    "            total += 1\n",
    "\n",
    "    return matches / total if total > 0 else 0.0\n",
    "\n",
    "columns_to_tokenize = ['title', 'content']\n",
    "accuracy = reconstruction_accuracy(df, columns_to_tokenize, tokenizer)\n",
    "print(f\"Total reconstruction accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: depo plumpang terbakar, anggota dpr minta pertamina pastikan pasokan bbm tak terganggu\n",
      "Tokens: ['▁de', 'po', '▁plu', 'mpang', '▁terbakar', ',', '▁anggota', '▁d', 'pr', '▁minta', '▁per', 'tamina', '▁pastikan', '▁paso', 'kan', '▁', 'bb', 'm', '▁tak', '▁ter', 'ganggu']\n",
      "Reconstructed: depo plumpang terbakar, anggota dpr minta pertamina pastikan pasokan bbm tak terganggu\n",
      "Original: jokowi perintahkan wapres ma'ruf amin tinjau lokasi kebakaran depo plumpang\n",
      "Tokens: ['▁jo', 'kowi', '▁perintah', 'kan', '▁wa', 'pres', '▁ma', \"'\", 'ruf', '▁amin', '▁tin', 'jau', '▁lokasi', '▁kebakaran', '▁de', 'po', '▁plu', 'mpang']\n",
      "Reconstructed: jokowi perintahkan wapres ma'ruf amin tinjau lokasi kebakaran depo plumpang\n",
      "Original: hnw mendukung jamaah umroh first travel dapatkan haknya\n",
      "Tokens: ['▁h', 'n', 'w', '▁mendukung', '▁ja', 'ma', 'ah', '▁um', 'roh', '▁first', '▁travel', '▁dapatkan', '▁hak', 'nya']\n",
      "Reconstructed: hnw mendukung jamaah umroh first travel dapatkan haknya\n",
      "Original: tim dokkes polri telah terima 14 kantong jenazah korban kebakaran depo plumpang\n",
      "Tokens: ['▁tim', '▁dok', 'kes', '▁pol', 'ri', '▁telah', '▁terima', '▁14', '▁kan', 'tong', '▁jenazah', '▁korban', '▁kebakaran', '▁de', 'po', '▁plu', 'mpang']\n",
      "Reconstructed: tim dokkes polri telah terima 14 kantong jenazah korban kebakaran depo plumpang\n",
      "Original: bamsoet ajak komunitas otomotif kembangkan perekonomian nasional\n",
      "Tokens: ['▁bam', 'so', 'et', '▁a', 'jak', '▁komunitas', '▁oto', 'motif', '▁ke', 'mbang', 'kan', '▁perekonomian', '▁nasional']\n",
      "Reconstructed: bamsoet ajak komunitas otomotif kembangkan perekonomian nasional\n",
      "Original: tempo.co, jakarta - anggota komisi 7 dpr ri rofik hananto menyayangkan terjadinya insiden kebakaran yang disebabkan oleh bocornya depo plumpang, jakarta utara, pada jumat, 3 maret 2023.\"turut berbela sungkawa terhadap masyarakat sipil yang terdampak, apalagi ini daerah padat penduduk. pertamina harus tanggung jawab,\" kata dia dalam keterangan di jakarta sabtu, 4 maret 2024.rofik mengatakan pertamina serta pihak terkait harus memastikan keselamatan dan keamanan warga yang tinggal di sekitar lokasi.pipa bbm yang terbakar itu merupakan bagian dari terminal bahan bakar minyak (tbbm) plumpang. tbbm plumpang dinilai sebagai salah satu terminal bbm terpenting di indonesia, sehingga rofik juga menegaskan pertamina harus memastikan pasokan bahan bakar minyak tetap aman meski ada insiden tersebut.\"plumpang menyuplai sekitar 20 persen kebutuhan bbm harian di indonesia, atau sekitar 25 persen dari total kebutuhan spbu pertamina. maka tindakan selanjutnya adalah bagaimana memastikan suplai bbm tidak terganggu,\" katanya.rofik juga menyinggung kejadian kilang minyak milik pertamina yang sebelumnya pernah terjadi kejadian serupa, seperti kilang balikpapan pada maret 2022 lalu. terhitung 2 tahun terakhir ini, kata dia, sudah 5 fasilitas migas milik pertamina mengalami insiden kebakaran.\"menyayangkan terjadinya musibah kebakaran ini, apalagi insiden kebakaran bukan kali pertama di fasilitas migas, ini terus berulang. pertamina harus benahi sistem pengamanan dan sop yang ada,\" kata dia.rofik mengharapkan adanya pembenahan menyeluruh terhadap sistem pengamanan serta sop yang ada dalam lingkup pertamina untuk mengamankan baik fasilitas migas, pekerja, maupun masyarakat sekitar. menurutnya pembenahan diperlukan agar pertamina tidak abai terhadap aspek pengamanan fasilitas migas.\"investigasi menyeluruh dan tuntas, serta meminta komitmen pertamina memperbaiki sistem keamanan kilang minyak maupun depo bbm, seringnya kebakaran terjadi mengindikasikan pertamina abai terhadap pengamanan kilang,\" ujarnya.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Tokens: ['▁tempo', '.', 'co', ',', '▁ja', 'karta', '▁-', '▁anggota', '▁komisi', '▁7', '▁d', 'pr', '▁ri', '▁ro', 'fik', '▁han', 'anto', '▁men', 'yay', 'angkan', '▁terjadinya', '▁in', 'siden', '▁kebakaran', '▁yang', '▁disebabkan', '▁oleh', '▁bo', 'cor', 'nya', '▁de', 'po', '▁plu', 'mpang', ',', '▁ja', 'karta', '▁u', 'tara', ',', '▁pada', '▁ju', 'mat', ',', '▁3', '▁mare', 't', '▁2023', '.\"', 'tur', 'ut', '▁ber', 'bela', '▁sung', 'kawa', '▁terhadap', '▁masyarakat', '▁si', 'pil', '▁yang', '▁ter', 'd', 'ampak', ',', '▁apalagi', '▁ini', '▁daerah', '▁pada', 't', '▁penduduk', '.', '▁per', 'tamina', '▁harus', '▁tanggung', '▁jawab', ',', '\"', '▁kata', '▁dia', '▁dalam', '▁keterangan', '▁di', '▁ja', 'karta', '▁sab', 'tu', ',', '▁4', '▁mare', 't', '▁20', '24.', 'ro', 'fik', '▁mengatakan', '▁per', 'tamina', '▁serta', '▁pihak', '▁terkait', '▁harus', '▁memastikan', '▁keselamatan', '▁dan', '▁keamanan', '▁warga', '▁yang', '▁tinggal', '▁di', '▁sekitar', '▁lokasi', '.', 'pi', 'pa', '▁', 'bb', 'm', '▁yang', '▁terbakar', '▁itu', '▁merupakan', '▁bagian', '▁dari', '▁terminal', '▁bahan', '▁bakar', '▁minyak', '▁(', 't', 'bb', 'm', ')', '▁plu', 'mpang', '.', '▁t', 'bb', 'm', '▁plu', 'mpang', '▁di', 'nilai', '▁sebagai', '▁salah', '▁satu', '▁terminal', '▁', 'bb', 'm', '▁terpenting', '▁di', '▁indonesia', ',', '▁sehingga', '▁ro', 'fik', '▁juga', '▁menegaskan', '▁per', 'tamina', '▁harus', '▁memastikan', '▁paso', 'kan', '▁bahan', '▁bakar', '▁minyak', '▁tetap', '▁aman', '▁meski', '▁ada', '▁in', 'siden', '▁tersebut', '.\"', 'plu', 'mpang', '▁menyu', 'pla', 'i', '▁sekitar', '▁20', '▁persen', '▁kebutuhan', '▁', 'bb', 'm', '▁harian', '▁di', '▁indonesia', ',', '▁atau', '▁sekitar', '▁25', '▁persen', '▁dari', '▁total', '▁kebutuhan', '▁sp', 'bu', '▁per', 'tamina', '.', '▁maka', '▁tindakan', '▁selanjutnya', '▁adalah', '▁bagaimana', '▁memastikan', '▁sup', 'lai', '▁', 'bb', 'm', '▁tidak', '▁ter', 'ganggu', ',', '\"', '▁katanya', '.', 'ro', 'fik', '▁juga', '▁menyi', 'nggung', '▁kejadian', '▁ki', 'lang', '▁minyak', '▁milik', '▁per', 'tamina', '▁yang', '▁sebelumnya', '▁pernah', '▁terjadi', '▁kejadian', '▁serupa', ',', '▁seperti', '▁ki', 'lang', '▁balik', 'papa', 'n', '▁pada', '▁mare', 't', '▁2022', '▁lalu', '.', '▁ter', 'hitung', '▁2', '▁tahun', '▁terakhir', '▁ini', ',', '▁kata', '▁dia', ',', '▁sudah', '▁5', '▁fasilitas', '▁mig', 'as', '▁milik', '▁per', 'tamina', '▁mengalami', '▁in', 'siden', '▁kebakaran', '.\"', 'men', 'yay', 'angkan', '▁terjadinya', '▁musi', 'bah', '▁kebakaran', '▁ini', ',', '▁apalagi', '▁in', 'siden', '▁kebakaran', '▁bukan', '▁kali', '▁pertama', '▁di', '▁fasilitas', '▁mig', 'as', ',', '▁ini', '▁terus', '▁berulang', '.', '▁per', 'tamina', '▁harus', '▁ben', 'ahi', '▁sistem', '▁penga', 'manan', '▁dan', '▁sop', '▁yang', '▁ada', ',', '\"', '▁kata', '▁dia', '.', 'ro', 'fik', '▁mengharapkan', '▁adanya', '▁pembe', 'na', 'han', '▁menyeluruh', '▁terhadap', '▁sistem', '▁penga', 'manan', '▁serta', '▁sop', '▁yang', '▁ada', '▁dalam', '▁ling', 'kup', '▁per', 'tamina', '▁untuk', '▁menga', 'man', 'kan', '▁baik', '▁fasilitas', '▁mig', 'as', ',', '▁pekerja', ',', '▁maupun', '▁masyarakat', '▁sekitar', '.', '▁menurut', 'nya', '▁pembe', 'na', 'han', '▁diperlukan', '▁agar', '▁per', 'tamina', '▁tidak', '▁aba', 'i', '▁terhadap', '▁aspek', '▁penga', 'manan', '▁fasilitas', '▁mig', 'as', '.\"', 'invest', 'iga', 'si', '▁menyeluruh', '▁dan', '▁tu', 'ntas', ',', '▁serta', '▁meminta', '▁komitmen', '▁per', 'tamina', '▁memperbaiki', '▁sistem', '▁keamanan', '▁ki', 'lang', '▁minyak', '▁maupun', '▁de', 'po', '▁', 'bb', 'm', ',', '▁sering', 'nya', '▁kebakaran', '▁terjadi', '▁meng', 'indik', 'asikan', '▁per', 'tamina', '▁aba', 'i', '▁terhadap', '▁penga', 'manan', '▁ki', 'lang', ',', '\"', '▁ujarnya', '.', 'pili', 'han', '▁editor', ':', 'profil', '▁de', 'po', '▁per', 'tamina', '▁plu', 'mpang', ',', '▁pema', 'sok', '▁20', '▁persen', '▁paso', 'kan', '▁', 'bb', 'm', '▁di', '▁seluruh', '▁indonesia']\n",
      "Reconstructed: tempo.co, jakarta - anggota komisi 7 dpr ri rofik hananto menyayangkan terjadinya insiden kebakaran yang disebabkan oleh bocornya depo plumpang, jakarta utara, pada jumat, 3 maret 2023.\"turut berbela sungkawa terhadap masyarakat sipil yang terdampak, apalagi ini daerah padat penduduk. pertamina harus tanggung jawab,\" kata dia dalam keterangan di jakarta sabtu, 4 maret 2024.rofik mengatakan pertamina serta pihak terkait harus memastikan keselamatan dan keamanan warga yang tinggal di sekitar lokasi.pipa bbm yang terbakar itu merupakan bagian dari terminal bahan bakar minyak (tbbm) plumpang. tbbm plumpang dinilai sebagai salah satu terminal bbm terpenting di indonesia, sehingga rofik juga menegaskan pertamina harus memastikan pasokan bahan bakar minyak tetap aman meski ada insiden tersebut.\"plumpang menyuplai sekitar 20 persen kebutuhan bbm harian di indonesia, atau sekitar 25 persen dari total kebutuhan spbu pertamina. maka tindakan selanjutnya adalah bagaimana memastikan suplai bbm tidak terganggu,\" katanya.rofik juga menyinggung kejadian kilang minyak milik pertamina yang sebelumnya pernah terjadi kejadian serupa, seperti kilang balikpapan pada maret 2022 lalu. terhitung 2 tahun terakhir ini, kata dia, sudah 5 fasilitas migas milik pertamina mengalami insiden kebakaran.\"menyayangkan terjadinya musibah kebakaran ini, apalagi insiden kebakaran bukan kali pertama di fasilitas migas, ini terus berulang. pertamina harus benahi sistem pengamanan dan sop yang ada,\" kata dia.rofik mengharapkan adanya pembenahan menyeluruh terhadap sistem pengamanan serta sop yang ada dalam lingkup pertamina untuk mengamankan baik fasilitas migas, pekerja, maupun masyarakat sekitar. menurutnya pembenahan diperlukan agar pertamina tidak abai terhadap aspek pengamanan fasilitas migas.\"investigasi menyeluruh dan tuntas, serta meminta komitmen pertamina memperbaiki sistem keamanan kilang minyak maupun depo bbm, seringnya kebakaran terjadi mengindikasikan pertamina abai terhadap pengamanan kilang,\" ujarnya.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Original: tempo.co, jakarta - presiden joko widodo atau jokowi memerintahkan wakil presiden ma'ruf amin untuk meninjau langsung lokasi kebakaran depo pertamina di plumpang, jakarta utara. kebakaran besar di lokasi tersebut terjadi pada jumat malam, 3 maret 2023, dan mengakibatkan belasan warga di sekitar depo tewas.\"presiden tidak ke plumpang hari ini. tapi, presiden sudah berkoordinasi dengan wapres yang akan meninjau hari ini,\" ujar deputi bidang protokol, pers, dan media sekretariat presiden bey machmudin saat dihubungi, sabtu, 4 februari 2023.selain memerintahkan ma'ruf amin, bey menyebut jokowi juga telah memberikan arahan kepada kapolri jenderal listyo sigit prabowo, menteri bumn erick thohir, dan penjabat gubernur dki jakarta heru budi hartono soal kunjungan ke lokasi.\"intinya presiden minta untuk mengutamakan evakuasi korban dan penanganan warga terdampak,\" kata bey.kronologi kebakarandepo pertamina di plumpang, jakarta utara, terbakar pada jumat malam, 3 maret 2023, pukul 20.20 wib. kepala dinas penanggulangan kebakaran dan penyelamatan dki jakarta, satriadi gunawan, mengatakan, objek kebakaran tersebut adalah pipa bensin.sementara itu, berdasarkan kesaksian warga, tercium aroma bensin yang menyengat sebelum kebakaran terjadi. dilansir dari antara, salah seorang warga, pandi mengatakan, ada bau bensin yang santer sebelum kejadian saat ia melintas di daerah tersebut.hingga kini belum diketahui penyebab kebakaran hebat tersebut. namun, pihak pertamina mengaku masih menginvestigasi penyebab insiden itu.\"penyebab kejadian masih dalam proses investigasi,\" kata area manager communication, relation & csr pertamina patra niaga regional jawa bagian barat eko kristiawan.eko juga menambahkan pihaknya saat ini fokus pada penanganan kebakaran pipa penerimaan bbm di integrated terminal bbm jakarta, plumpang.setidaknya 17 orang dilaporkan meninggal dunia akibat insiden ini. sementara 50 orang mengalami luka-luka dengan berbagai tingkat keparahan.api yang menyambar hingga ke dua kawasan rumah warga (rw) ini juga mengakibatkan ratusan orang terpaksa mengungsi. badan penanggulangan bencana daerah (bpbd) dki jakarta menyatakan warga yang mengungsi akibat kebakaran mencapai 579 jiwa. mereka tersebar di enam titik pengungsian.\"pengungsi info sementara 579 jiwa,\" demikian keterangan bpbd dki jakarta, sabtu, 4 maret 2024.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Tokens: ['▁tempo', '.', 'co', ',', '▁ja', 'karta', '▁-', '▁presiden', '▁joko', '▁wid', 'odo', '▁atau', '▁jo', 'kowi', '▁memerintah', 'kan', '▁wakil', '▁presiden', '▁ma', \"'\", 'ruf', '▁amin', '▁untuk', '▁meninjau', '▁langsung', '▁lokasi', '▁kebakaran', '▁de', 'po', '▁per', 'tamina', '▁di', '▁plu', 'mpang', ',', '▁ja', 'karta', '▁u', 'tara', '.', '▁kebakaran', '▁besar', '▁di', '▁lokasi', '▁tersebut', '▁terjadi', '▁pada', '▁ju', 'mat', '▁malam', ',', '▁3', '▁mare', 't', '▁2023', ',', '▁dan', '▁mengakibatkan', '▁belas', 'an', '▁warga', '▁di', '▁sekitar', '▁de', 'po', '▁te', 'was', '.\"', 'pres', 'iden', '▁tidak', '▁ke', '▁plu', 'mpang', '▁hari', '▁ini', '.', '▁tapi', ',', '▁presiden', '▁sudah', '▁ber', 'ko', 'ordina', 'si', '▁dengan', '▁wa', 'pres', '▁yang', '▁akan', '▁meninjau', '▁hari', '▁ini', ',', '\"', '▁ujar', '▁de', 'puti', '▁bidang', '▁protokol', ',', '▁per', 's', ',', '▁dan', '▁media', '▁sekretari', 'at', '▁presiden', '▁be', 'y', '▁mach', 'mu', 'din', '▁saat', '▁dihubungi', ',', '▁sab', 'tu', ',', '▁4', '▁februari', '▁2023', '.', 'se', 'lain', '▁memerintah', 'kan', '▁ma', \"'\", 'ruf', '▁amin', ',', '▁be', 'y', '▁menyebut', '▁jo', 'kowi', '▁juga', '▁telah', '▁memberikan', '▁a', 'rahan', '▁kepada', '▁ka', 'pol', 'ri', '▁je', 'nder', 'al', '▁listy', 'o', '▁sig', 'it', '▁pra', 'bow', 'o', ',', '▁menteri', '▁bu', 'mn', '▁e', 'rick', '▁tho', 'hir', ',', '▁dan', '▁penja', 'bat', '▁gubernur', '▁d', 'ki', '▁ja', 'karta', '▁her', 'u', '▁budi', '▁har', 'tono', '▁soal', '▁kunjungan', '▁ke', '▁lokasi', '.\"', 'inti', 'nya', '▁presiden', '▁minta', '▁untuk', '▁mengutamakan', '▁evaku', 'asi', '▁korban', '▁dan', '▁penanganan', '▁warga', '▁ter', 'd', 'ampak', ',', '\"', '▁kata', '▁be', 'y', '.', 'kron', 'ologi', '▁kebakaran', 'de', 'po', '▁per', 'tamina', '▁di', '▁plu', 'mpang', ',', '▁ja', 'karta', '▁u', 'tara', ',', '▁terbakar', '▁pada', '▁ju', 'mat', '▁malam', ',', '▁3', '▁mare', 't', '▁2023', ',', '▁pukul', '▁20.', '20', '▁w', 'ib', '.', '▁kepala', '▁din', 'as', '▁pena', 'nggu', 'langan', '▁kebakaran', '▁dan', '▁penye', 'lama', 'tan', '▁d', 'ki', '▁ja', 'karta', ',', '▁satria', 'di', '▁guna', 'wan', ',', '▁mengatakan', ',', '▁objek', '▁kebakaran', '▁tersebut', '▁adalah', '▁pi', 'pa', '▁bensin', '.', 'se', 'mentar', 'a', '▁itu', ',', '▁berdasarkan', '▁kes', 'aksi', 'an', '▁warga', ',', '▁ter', 'cium', '▁aroma', '▁bensin', '▁yang', '▁menye', 'ng', 'at', '▁sebelum', '▁kebakaran', '▁terjadi', '.', '▁di', 'lan', 'sir', '▁dari', '▁antara', ',', '▁salah', '▁seorang', '▁warga', ',', '▁', 'pandi', '▁mengatakan', ',', '▁ada', '▁bau', '▁bensin', '▁yang', '▁sant', 'er', '▁sebelum', '▁kejadian', '▁saat', '▁ia', '▁meli', 'ntas', '▁di', '▁daerah', '▁tersebut', '.', 'hing', 'ga', '▁kini', '▁belum', '▁diketahui', '▁penyebab', '▁kebakaran', '▁hebat', '▁tersebut', '.', '▁namun', ',', '▁pihak', '▁per', 'tamina', '▁mengaku', '▁masih', '▁meng', 'invest', 'iga', 'si', '▁penyebab', '▁in', 'siden', '▁itu', '.\"', 'pen', 'ye', 'bab', '▁kejadian', '▁masih', '▁dalam', '▁proses', '▁investiga', 'si', ',', '\"', '▁kata', '▁area', '▁manager', '▁communication', ',', '▁relation', '▁&', '▁cs', 'r', '▁per', 'tamina', '▁patra', '▁ni', 'aga', '▁regional', '▁ja', 'wa', '▁bagian', '▁barat', '▁eko', '▁krist', 'i', 'awan', '.', 'eko', '▁juga', '▁menambahkan', '▁pihaknya', '▁saat', '▁ini', '▁fokus', '▁pada', '▁penanganan', '▁kebakaran', '▁pi', 'pa', '▁penerima', 'an', '▁', 'bb', 'm', '▁di', '▁integrat', 'ed', '▁terminal', '▁', 'bb', 'm', '▁ja', 'karta', ',', '▁plu', 'mpang', '.', 'se', 'tidak', 'nya', '▁17', '▁orang', '▁dilaporkan', '▁meninggal', '▁dunia', '▁akibat', '▁in', 'siden', '▁ini', '.', '▁sementara', '▁50', '▁orang', '▁mengalami', '▁luka', '-', 'luka', '▁dengan', '▁berbagai', '▁tingkat', '▁ke', 'para', 'han', '.', 'api', '▁yang', '▁me', 'nya', 'mbar', '▁hingga', '▁ke', '▁dua', '▁kawasan', '▁rumah', '▁warga', '▁(', 'r', 'w', ')', '▁ini', '▁juga', '▁mengakibatkan', '▁ratusan', '▁orang', '▁terpaksa', '▁meng', 'ungs', 'i', '.', '▁badan', '▁pena', 'nggu', 'langan', '▁bencana', '▁daerah', '▁(', 'b', 'p', 'bd', ')', '▁d', 'ki', '▁ja', 'karta', '▁menyatakan', '▁warga', '▁yang', '▁meng', 'ungs', 'i', '▁akibat', '▁kebakaran', '▁mencapai', '▁', '579', '▁jiwa', '.', '▁mereka', '▁tersebar', '▁di', '▁enam', '▁titik', '▁peng', 'ung', 'sian', '.\"', 'peng', 'ungs', 'i', '▁info', '▁sementara', '▁', '579', '▁jiwa', ',', '\"', '▁demikian', '▁keterangan', '▁bp', 'bd', '▁d', 'ki', '▁ja', 'karta', ',', '▁sab', 'tu', ',', '▁4', '▁mare', 't', '▁20', '24.', 'pili', 'han', '▁editor', ':', 'profil', '▁de', 'po', '▁per', 'tamina', '▁plu', 'mpang', ',', '▁pema', 'sok', '▁20', '▁persen', '▁paso', 'kan', '▁', 'bb', 'm', '▁di', '▁seluruh', '▁indonesia']\n",
      "Reconstructed: tempo.co, jakarta - presiden joko widodo atau jokowi memerintahkan wakil presiden ma'ruf amin untuk meninjau langsung lokasi kebakaran depo pertamina di plumpang, jakarta utara. kebakaran besar di lokasi tersebut terjadi pada jumat malam, 3 maret 2023, dan mengakibatkan belasan warga di sekitar depo tewas.\"presiden tidak ke plumpang hari ini. tapi, presiden sudah berkoordinasi dengan wapres yang akan meninjau hari ini,\" ujar deputi bidang protokol, pers, dan media sekretariat presiden bey machmudin saat dihubungi, sabtu, 4 februari 2023.selain memerintahkan ma'ruf amin, bey menyebut jokowi juga telah memberikan arahan kepada kapolri jenderal listyo sigit prabowo, menteri bumn erick thohir, dan penjabat gubernur dki jakarta heru budi hartono soal kunjungan ke lokasi.\"intinya presiden minta untuk mengutamakan evakuasi korban dan penanganan warga terdampak,\" kata bey.kronologi kebakarandepo pertamina di plumpang, jakarta utara, terbakar pada jumat malam, 3 maret 2023, pukul 20.20 wib. kepala dinas penanggulangan kebakaran dan penyelamatan dki jakarta, satriadi gunawan, mengatakan, objek kebakaran tersebut adalah pipa bensin.sementara itu, berdasarkan kesaksian warga, tercium aroma bensin yang menyengat sebelum kebakaran terjadi. dilansir dari antara, salah seorang warga, pandi mengatakan, ada bau bensin yang santer sebelum kejadian saat ia melintas di daerah tersebut.hingga kini belum diketahui penyebab kebakaran hebat tersebut. namun, pihak pertamina mengaku masih menginvestigasi penyebab insiden itu.\"penyebab kejadian masih dalam proses investigasi,\" kata area manager communication, relation & csr pertamina patra niaga regional jawa bagian barat eko kristiawan.eko juga menambahkan pihaknya saat ini fokus pada penanganan kebakaran pipa penerimaan bbm di integrated terminal bbm jakarta, plumpang.setidaknya 17 orang dilaporkan meninggal dunia akibat insiden ini. sementara 50 orang mengalami luka-luka dengan berbagai tingkat keparahan.api yang menyambar hingga ke dua kawasan rumah warga (rw) ini juga mengakibatkan ratusan orang terpaksa mengungsi. badan penanggulangan bencana daerah (bpbd) dki jakarta menyatakan warga yang mengungsi akibat kebakaran mencapai 579 jiwa. mereka tersebar di enam titik pengungsian.\"pengungsi info sementara 579 jiwa,\" demikian keterangan bpbd dki jakarta, sabtu, 4 maret 2024.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Original: info nasional - wakil ketua mpr ri dr. h. m. hidayat nur wahid ma., atau hnw menerima kunjungan perwakilan korban kasus biro perjalanan haji dan umroh first travel, yang tergabung dalam paguyuban first travel indonesia. pertemuan tersebut berlangsung di ruang kerja wakil ketua mpr gedung nusantara 3 komplek senayan, jumat, 3 maret 2023.delegasi paguyuban first travel indonesia dipimpin abdul rasyid siq, s. thi, m.si., salah satu tujuan kedatangan perwakilan mereka bertemu hnw, adalah untuk meminta bantuan dan dukungan terkait putusan kasasi mahkamah agung nomor: 365 pk/pid.sus/2022 tanggal 23 mei 2022.dalam pk, itu mahkamah agung (ma) memutuskan bahwa seluruh aset dalam kasus pt first anugerah karya wisata (first travel) dikembalikan ke jamaah atau korban. tapi, hingga kini keputusan tersebut belum bisa dieksekusi.bahkan, kejaksaan negeri (kejari) depok selaku eksekutor tengah menunggu putusan lengkap peninjauan kembali (pk) perkara tersebut. kepada hnw, abdul rasyid mengatakan, para calon jamaah umroh berharap bisa diberangkatkan ke tanah suci mekah untuk melaksanakan ibadah umroh.\"keberangkatan ke mekah, lebih penting dibanding menerima pengembalian biaya umroh yang telah kami bayarkan pada 2016-2017,\" kata abdul.ia berharap, pemerintah dalam hal ini kementerian agama membantu calon jamaah umroh. kami berharap pemerintah hadir dalam perkara ini, dan bertanggungjawab memberangkatkan seluruh jamaah umroh korban first travel, sebagaimana pernah mereka janjikan, ujar abdul.wakil ketua mpr hidayat nur wahid menyampaikan rasa prihatin dan ikut bersimpati terhadap jamaah umroh yang gagal diberangkatkan biro perjalanan haji dan umroh first travel. hnw memahami, betapa kecewa dan sedihnya jamaah yang gagal diberangkatkan.apalagi, tidak sedikit diantara mereka yang menabung selama bertahun-tahun, mengumpulkan uang untuk membayar biaya umroh. persoalan umroh, menurut hnw kerap dibahas oleh komisi 8 dpr ri dengan pihak kementerian agama.bahkan, untuk menjamin agar ibadah umroh bisa berjalan dengan baik, komisi 8 mengusulkan selain adanya dirjen penyelenggaraan haji juga umroh. sayangnya persoalan haji lebih mendapat perhatian dibanding ibadah umroh.ini memang belum adil, pemerintah masih memberikan perhatiannya lebih besar kepada persoalan haji dari pada persoalan calon jemaah umroh, kata hnw.hidayat mendukung calon jamaah umroh yang tergabung dalam paguyuban first travel indonesia, tetap berusaha menuntut haknya agar bisa melaksanakan ibadah umroh. apalagi, mereka pernah dijanjikan oleh kementerian agama, untuk diberangkatkan umroh jika persoalan hukumnya telah inkracht.perwakilan calon jemaah umroh pun menyampaikan apresiasi dan terimakasih kepada hnw dengan berbagai saran konstruktif dan kesediaannya membantu para calon jemaah umroh. (*)\n",
      "Tokens: ['▁info', '▁nasional', '▁-', '▁wakil', '▁ketua', '▁mp', 'r', '▁ri', '▁dr', '.', '▁h', '.', '▁m', '.', '▁hid', 'ayat', '▁nur', '▁wa', 'hid', '▁ma', '.', ',', '▁atau', '▁h', 'n', 'w', '▁menerima', '▁kunjungan', '▁perwakilan', '▁korban', '▁kasus', '▁biro', '▁perjalanan', '▁haji', '▁dan', '▁um', 'roh', '▁first', '▁travel', ',', '▁yang', '▁ter', 'gabung', '▁dalam', '▁pag', 'uyu', 'ban', '▁first', '▁travel', '▁indonesia', '.', '▁pertemuan', '▁tersebut', '▁berlangsung', '▁di', '▁ruang', '▁kerja', '▁wakil', '▁ketua', '▁mp', 'r', '▁gedung', '▁nu', 's', 'antara', '▁3', '▁kom', 'plek', '▁se', 'na', 'yan', ',', '▁ju', 'mat', ',', '▁3', '▁mare', 't', '▁2023', '.', 'de', 'lega', 'si', '▁pag', 'uyu', 'ban', '▁first', '▁travel', '▁indonesia', '▁dipimpin', '▁ab', 'dul', '▁ras', 'y', 'id', '▁si', 'q', ',', '▁s', '.', '▁thi', ',', '▁m', '.', 'si', '.', ',', '▁salah', '▁satu', '▁tujuan', '▁kedatangan', '▁perwakilan', '▁mereka', '▁bertemu', '▁h', 'n', 'w', ',', '▁adalah', '▁untuk', '▁meminta', '▁bantuan', '▁dan', '▁dukungan', '▁terkait', '▁putus', 'an', '▁kas', 'asi', '▁mahkamah', '▁', 'agung', '▁nomor', ':', '▁365', '▁', 'pk', '/', 'pid', '.', 'sus', '/', '2022', '▁tanggal', '▁23', '▁mei', '▁2022', '.', 'dalam', '▁', 'pk', ',', '▁itu', '▁mahkamah', '▁', 'agung', '▁(', 'ma', ')', '▁memutuskan', '▁bahwa', '▁seluruh', '▁aset', '▁dalam', '▁kasus', '▁pt', '▁first', '▁anugerah', '▁karya', '▁wisata', '▁(', 'fir', 'st', '▁travel', ')', '▁dike', 'mbali', 'kan', '▁ke', '▁ja', 'ma', 'ah', '▁atau', '▁korban', '.', '▁tapi', ',', '▁hingga', '▁kini', '▁keputusan', '▁tersebut', '▁belum', '▁bisa', '▁die', 'kse', 'kusi', '.', 'bah', 'kan', ',', '▁ke', 'jaks', 'aan', '▁negeri', '▁(', 'kej', 'ari', ')', '▁de', 'pok', '▁selaku', '▁eks', 'e', 'ku', 'tor', '▁tengah', '▁menunggu', '▁putus', 'an', '▁lengkap', '▁pe', 'nin', 'ja', 'uan', '▁kembali', '▁(', 'pk', ')', '▁perkara', '▁tersebut', '.', '▁kepada', '▁h', 'n', 'w', ',', '▁ab', 'dul', '▁ras', 'y', 'id', '▁mengatakan', ',', '▁para', '▁calon', '▁ja', 'ma', 'ah', '▁um', 'roh', '▁berharap', '▁bisa', '▁di', 'ber', 'angkat', 'kan', '▁ke', '▁tanah', '▁suci', '▁me', 'kah', '▁untuk', '▁melaksanakan', '▁ibadah', '▁um', 'roh', '.\"', 'ke', 'ber', 'angkat', 'an', '▁ke', '▁me', 'kah', ',', '▁lebih', '▁penting', '▁dibanding', '▁menerima', '▁penge', 'mbali', 'an', '▁biaya', '▁um', 'roh', '▁yang', '▁telah', '▁kami', '▁bayar', 'kan', '▁pada', '▁2016-2017', ',', '\"', '▁kata', '▁ab', 'dul', '.', 'ia', '▁berharap', ',', '▁pemerintah', '▁dalam', '▁hal', '▁ini', '▁kementerian', '▁agama', '▁membantu', '▁calon', '▁ja', 'ma', 'ah', '▁um', 'roh', '.', '▁kami', '▁berharap', '▁pemerintah', '▁hadir', '▁dalam', '▁perkara', '▁ini', ',', '▁dan', '▁', 'bertanggungjawab', '▁member', 'angkat', 'kan', '▁seluruh', '▁ja', 'ma', 'ah', '▁um', 'roh', '▁korban', '▁first', '▁travel', ',', '▁sebagaimana', '▁pernah', '▁mereka', '▁janji', 'kan', ',', '▁ujar', '▁ab', 'dul', '.', 'wakil', '▁ketua', '▁mp', 'r', '▁hid', 'ayat', '▁nur', '▁wa', 'hid', '▁menyampaikan', '▁rasa', '▁pri', 'hat', 'in', '▁dan', '▁ikut', '▁ber', 'sim', 'pati', '▁terhadap', '▁ja', 'ma', 'ah', '▁um', 'roh', '▁yang', '▁gagal', '▁di', 'ber', 'angkat', 'kan', '▁biro', '▁perjalanan', '▁haji', '▁dan', '▁um', 'roh', '▁first', '▁travel', '.', '▁h', 'n', 'w', '▁memahami', ',', '▁betapa', '▁kecewa', '▁dan', '▁sedih', 'nya', '▁ja', 'ma', 'ah', '▁yang', '▁gagal', '▁di', 'ber', 'angkat', 'kan', '.', 'apa', 'lagi', ',', '▁tidak', '▁sedikit', '▁diantara', '▁mereka', '▁yang', '▁mena', 'bung', '▁selama', '▁ber', 'tahun', '-', 'tahun', ',', '▁mengumpulkan', '▁uang', '▁untuk', '▁membayar', '▁biaya', '▁um', 'roh', '.', '▁persoalan', '▁um', 'roh', ',', '▁menurut', '▁h', 'n', 'w', '▁kerap', '▁dibahas', '▁oleh', '▁komisi', '▁8', '▁d', 'pr', '▁ri', '▁dengan', '▁pihak', '▁kementerian', '▁agama', '.', 'bah', 'kan', ',', '▁untuk', '▁menjamin', '▁agar', '▁ibadah', '▁um', 'roh', '▁bisa', '▁berjalan', '▁dengan', '▁baik', ',', '▁komisi', '▁8', '▁mengu', 'sul', 'kan', '▁selain', '▁adanya', '▁dir', 'jen', '▁penyelenggaraan', '▁haji', '▁juga', '▁um', 'roh', '.', '▁sayang', 'nya', '▁persoalan', '▁haji', '▁lebih', '▁mendapat', '▁perhatian', '▁dibanding', '▁ibadah', '▁um', 'roh', '.', 'ini', '▁memang', '▁belum', '▁adil', ',', '▁pemerintah', '▁masih', '▁memberikan', '▁perhatian', 'nya', '▁lebih', '▁besar', '▁kepada', '▁persoalan', '▁haji', '▁dari', '▁pada', '▁persoalan', '▁calon', '▁jemaah', '▁um', 'roh', ',', '▁kata', '▁h', 'n', 'w', '.', 'hid', 'ayat', '▁mendukung', '▁calon', '▁ja', 'ma', 'ah', '▁um', 'roh', '▁yang', '▁ter', 'gabung', '▁dalam', '▁pag', 'uyu', 'ban', '▁first', '▁travel', '▁indonesia', ',', '▁tetap', '▁berusaha', '▁menuntut', '▁hak', 'nya', '▁agar', '▁bisa', '▁melaksanakan', '▁ibadah', '▁um', 'roh', '.', '▁apalagi', ',', '▁mereka', '▁pernah', '▁dija', 'nji', 'kan', '▁oleh', '▁kementerian', '▁agama', ',', '▁untuk', '▁di', 'ber', 'angkat', 'kan', '▁um', 'roh', '▁jika', '▁persoalan', '▁hukum', 'nya', '▁telah', '▁in', 'kracht', '.', 'per', 'wakil', 'an', '▁calon', '▁jemaah', '▁um', 'roh', '▁pun', '▁menyampaikan', '▁apre', 'si', 'asi', '▁dan', '▁terimakasih', '▁kepada', '▁h', 'n', 'w', '▁dengan', '▁berbagai', '▁saran', '▁', 'konstrukt', 'if', '▁dan', '▁ke', 'sedia', 'annya', '▁membantu', '▁para', '▁calon', '▁jemaah', '▁um', 'roh', '.', '▁(*)']\n",
      "Reconstructed: info nasional - wakil ketua mpr ri dr. h. m. hidayat nur wahid ma., atau hnw menerima kunjungan perwakilan korban kasus biro perjalanan haji dan umroh first travel, yang tergabung dalam paguyuban first travel indonesia. pertemuan tersebut berlangsung di ruang kerja wakil ketua mpr gedung nusantara 3 komplek senayan, jumat, 3 maret 2023.delegasi paguyuban first travel indonesia dipimpin abdul rasyid siq, s. thi, m.si., salah satu tujuan kedatangan perwakilan mereka bertemu hnw, adalah untuk meminta bantuan dan dukungan terkait putusan kasasi mahkamah agung nomor: 365 pk/pid.sus/2022 tanggal 23 mei 2022.dalam pk, itu mahkamah agung (ma) memutuskan bahwa seluruh aset dalam kasus pt first anugerah karya wisata (first travel) dikembalikan ke jamaah atau korban. tapi, hingga kini keputusan tersebut belum bisa dieksekusi.bahkan, kejaksaan negeri (kejari) depok selaku eksekutor tengah menunggu putusan lengkap peninjauan kembali (pk) perkara tersebut. kepada hnw, abdul rasyid mengatakan, para calon jamaah umroh berharap bisa diberangkatkan ke tanah suci mekah untuk melaksanakan ibadah umroh.\"keberangkatan ke mekah, lebih penting dibanding menerima pengembalian biaya umroh yang telah kami bayarkan pada 2016-2017,\" kata abdul.ia berharap, pemerintah dalam hal ini kementerian agama membantu calon jamaah umroh. kami berharap pemerintah hadir dalam perkara ini, dan bertanggungjawab memberangkatkan seluruh jamaah umroh korban first travel, sebagaimana pernah mereka janjikan, ujar abdul.wakil ketua mpr hidayat nur wahid menyampaikan rasa prihatin dan ikut bersimpati terhadap jamaah umroh yang gagal diberangkatkan biro perjalanan haji dan umroh first travel. hnw memahami, betapa kecewa dan sedihnya jamaah yang gagal diberangkatkan.apalagi, tidak sedikit diantara mereka yang menabung selama bertahun-tahun, mengumpulkan uang untuk membayar biaya umroh. persoalan umroh, menurut hnw kerap dibahas oleh komisi 8 dpr ri dengan pihak kementerian agama.bahkan, untuk menjamin agar ibadah umroh bisa berjalan dengan baik, komisi 8 mengusulkan selain adanya dirjen penyelenggaraan haji juga umroh. sayangnya persoalan haji lebih mendapat perhatian dibanding ibadah umroh.ini memang belum adil, pemerintah masih memberikan perhatiannya lebih besar kepada persoalan haji dari pada persoalan calon jemaah umroh, kata hnw.hidayat mendukung calon jamaah umroh yang tergabung dalam paguyuban first travel indonesia, tetap berusaha menuntut haknya agar bisa melaksanakan ibadah umroh. apalagi, mereka pernah dijanjikan oleh kementerian agama, untuk diberangkatkan umroh jika persoalan hukumnya telah inkracht.perwakilan calon jemaah umroh pun menyampaikan apresiasi dan terimakasih kepada hnw dengan berbagai saran konstruktif dan kesediaannya membantu para calon jemaah umroh. (*)\n",
      "Original: tempo.co, jakarta - tim kedokteran dan kesehatan (dokkes) polri telah menerima 14 kantong jenazah korban kebakaran depo plumpang, jakarta utara.\"pada hari ini, posko dvi sudah menerima 14 kantong jenazah. tim dvi pun langsung bekerja untuk melakukan identifikasi korban,\" kata kepala divisi humas polri irjen dedi prasetyo dalam keterangan tertulisnya, sabtu, 4 maret 2023.kebakaran depo plumpang terjadi pada jumat malam, 3 maret 2023. pada saat kejadian, kata dedi, tim dokkes polri mengirimkan 5 ambulans dan tim medis untuk mengevakuasi korban dan membantu dalam perawatan medis.tim dokkes polri mengirimkan korban luka ke beberapa rumah sakit terdekat guna mendapatkan perawatan lebih lanjut. tim dokkes polri juga telah mendirikan posko dvi di rumah sakit polri kramat jati.dedi menuturkan tim labfor hari ini sedang berkoordinasi dengan bareskrim dan ditreskrimum polda metro jaya untuk menyelidiki penyebab kebakaran dan melakukan olah tempat kejadian perkara (tkp).\"langkah yang dilakukan hari setelah clear dari hse (health safety environment) dari pertamina baru kita olah tkp. jumlah anggota sementara 9 orang. alat yang kita gunakan toolkid kebakaran, drone, alat ambil sampel abu arang dan gunakan teknologi remote sensing,\" ujarnya.sementara untuk tim inafis hari ini mem-back up polda metro untuk olah tkp bersama labfor dan bersama tim dvi dokkes untuk melakukan proses identifikasi korban meninggal dunia di rumah sakit polri kramat jati.sementara itu, untuk di lokasi kebakaran, dedi mengatakan, polri melakukan pengamanan terhadap lokasi kebakaran baik di depo plumpang, maupun lokasi rumah warga terdampak yang ditinggal mengungsi.polri juga mendirikan posko tanggap darurat kebakaran secara terpadu dan pengaduan orang hilang di depan halaman koramil koja. \"mendirikan dapur umum di pos polisi oleh sat brimobda pmj dan membantu posko pengungaian bpbd,\" katanya.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Tokens: ['▁tempo', '.', 'co', ',', '▁ja', 'karta', '▁-', '▁tim', '▁ke', 'do', 'kter', 'an', '▁dan', '▁kesehatan', '▁(', 'dok', 'kes', ')', '▁pol', 'ri', '▁telah', '▁menerima', '▁14', '▁kan', 'tong', '▁jenazah', '▁korban', '▁kebakaran', '▁de', 'po', '▁plu', 'mpang', ',', '▁ja', 'karta', '▁u', 'tara', '.\"', 'pada', '▁hari', '▁ini', ',', '▁po', 'sko', '▁dvi', '▁sudah', '▁menerima', '▁14', '▁kan', 'tong', '▁jenazah', '.', '▁tim', '▁dvi', '▁pun', '▁langsung', '▁bekerja', '▁untuk', '▁melakukan', '▁identifik', 'asi', '▁korban', ',', '\"', '▁kata', '▁kepala', '▁di', 'visi', '▁hum', 'as', '▁pol', 'ri', '▁ir', 'jen', '▁dedi', '▁pras', 'et', 'yo', '▁dalam', '▁keterangan', '▁tertulis', 'nya', ',', '▁sab', 'tu', ',', '▁4', '▁mare', 't', '▁2023', '.', 'ke', 'ba', 'karan', '▁de', 'po', '▁plu', 'mpang', '▁terjadi', '▁pada', '▁ju', 'mat', '▁malam', ',', '▁3', '▁mare', 't', '▁2023', '.', '▁pada', '▁saat', '▁kejadian', ',', '▁kata', '▁dedi', ',', '▁tim', '▁dok', 'kes', '▁pol', 'ri', '▁mengirimkan', '▁5', '▁ambulans', '▁dan', '▁tim', '▁med', 'is', '▁untuk', '▁menge', 'va', 'ku', 'asi', '▁korban', '▁dan', '▁membantu', '▁dalam', '▁perawatan', '▁med', 'is', '.', 'tim', '▁dok', 'kes', '▁pol', 'ri', '▁mengirimkan', '▁korban', '▁luka', '▁ke', '▁beberapa', '▁rumah', '▁sakit', '▁terdekat', '▁guna', '▁mendapatkan', '▁perawatan', '▁lebih', '▁lanjut', '.', '▁tim', '▁dok', 'kes', '▁pol', 'ri', '▁juga', '▁telah', '▁mendirikan', '▁po', 'sko', '▁dvi', '▁di', '▁rumah', '▁sakit', '▁pol', 'ri', '▁kram', 'at', '▁ja', 'ti', '.', 'de', 'di', '▁menu', 'tur', 'kan', '▁tim', '▁lab', 'for', '▁hari', '▁ini', '▁sedang', '▁ber', 'ko', 'ordina', 'si', '▁dengan', '▁bare', 's', 'krim', '▁dan', '▁di', 'tres', 'krim', 'um', '▁pol', 'da', '▁metro', '▁ja', 'ya', '▁untuk', '▁menye', 'lid', 'iki', '▁penyebab', '▁kebakaran', '▁dan', '▁melakukan', '▁o', 'lah', '▁tempat', '▁kejadian', '▁perkara', '▁(', 'tk', 'p', ').', '\"', 'langkah', '▁yang', '▁dilakukan', '▁hari', '▁setelah', '▁clear', '▁dari', '▁h', 'se', '▁(', 'health', '▁safety', '▁environment', ')', '▁dari', '▁per', 'tamina', '▁baru', '▁kita', '▁o', 'lah', '▁', 'tk', 'p', '.', '▁jumlah', '▁anggota', '▁sementara', '▁9', '▁orang', '.', '▁alat', '▁yang', '▁kita', '▁gunakan', '▁tool', 'kid', '▁kebakaran', ',', '▁drone', ',', '▁alat', '▁ambil', '▁sa', 'mpel', '▁abu', '▁a', 'rang', '▁dan', '▁gunakan', '▁teknologi', '▁remote', '▁sens', 'ing', ',', '\"', '▁ujarnya', '.', 'se', 'mentar', 'a', '▁untuk', '▁tim', '▁in', 'afi', 's', '▁hari', '▁ini', '▁mem', '-', 'back', '▁up', '▁pol', 'da', '▁metro', '▁untuk', '▁o', 'lah', '▁', 'tk', 'p', '▁bersama', '▁lab', 'for', '▁dan', '▁bersama', '▁tim', '▁dvi', '▁dok', 'kes', '▁untuk', '▁melakukan', '▁proses', '▁identifik', 'asi', '▁korban', '▁meninggal', '▁dunia', '▁di', '▁rumah', '▁sakit', '▁pol', 'ri', '▁kram', 'at', '▁ja', 'ti', '.', 'se', 'mentar', 'a', '▁itu', ',', '▁untuk', '▁di', '▁lokasi', '▁kebakaran', ',', '▁dedi', '▁mengatakan', ',', '▁pol', 'ri', '▁melakukan', '▁penga', 'manan', '▁terhadap', '▁lokasi', '▁kebakaran', '▁baik', '▁di', '▁de', 'po', '▁plu', 'mpang', ',', '▁maupun', '▁lokasi', '▁rumah', '▁warga', '▁ter', 'd', 'ampak', '▁yang', '▁di', 'tinggal', '▁meng', 'ungs', 'i', '.', 'pol', 'ri', '▁juga', '▁mendirikan', '▁po', 'sko', '▁', 'tanggap', '▁dar', 'urat', '▁kebakaran', '▁secara', '▁ter', 'padu', '▁dan', '▁penga', 'du', 'an', '▁orang', '▁hilang', '▁di', '▁depan', '▁halaman', '▁kora', 'mil', '▁koja', '.', '▁\"', 'mendi', 'rikan', '▁dapur', '▁umum', '▁di', '▁pos', '▁polisi', '▁oleh', '▁sat', '▁bri', 'mo', 'b', 'da', '▁pm', 'j', '▁dan', '▁membantu', '▁po', 'sko', '▁peng', 'unga', 'ian', '▁bp', 'bd', ',', '\"', '▁katanya', '.', 'pili', 'han', '▁editor', ':', 'profil', '▁de', 'po', '▁per', 'tamina', '▁plu', 'mpang', ',', '▁pema', 'sok', '▁20', '▁persen', '▁paso', 'kan', '▁', 'bb', 'm', '▁di', '▁seluruh', '▁indonesia']\n",
      "Reconstructed: tempo.co, jakarta - tim kedokteran dan kesehatan (dokkes) polri telah menerima 14 kantong jenazah korban kebakaran depo plumpang, jakarta utara.\"pada hari ini, posko dvi sudah menerima 14 kantong jenazah. tim dvi pun langsung bekerja untuk melakukan identifikasi korban,\" kata kepala divisi humas polri irjen dedi prasetyo dalam keterangan tertulisnya, sabtu, 4 maret 2023.kebakaran depo plumpang terjadi pada jumat malam, 3 maret 2023. pada saat kejadian, kata dedi, tim dokkes polri mengirimkan 5 ambulans dan tim medis untuk mengevakuasi korban dan membantu dalam perawatan medis.tim dokkes polri mengirimkan korban luka ke beberapa rumah sakit terdekat guna mendapatkan perawatan lebih lanjut. tim dokkes polri juga telah mendirikan posko dvi di rumah sakit polri kramat jati.dedi menuturkan tim labfor hari ini sedang berkoordinasi dengan bareskrim dan ditreskrimum polda metro jaya untuk menyelidiki penyebab kebakaran dan melakukan olah tempat kejadian perkara (tkp).\"langkah yang dilakukan hari setelah clear dari hse (health safety environment) dari pertamina baru kita olah tkp. jumlah anggota sementara 9 orang. alat yang kita gunakan toolkid kebakaran, drone, alat ambil sampel abu arang dan gunakan teknologi remote sensing,\" ujarnya.sementara untuk tim inafis hari ini mem-back up polda metro untuk olah tkp bersama labfor dan bersama tim dvi dokkes untuk melakukan proses identifikasi korban meninggal dunia di rumah sakit polri kramat jati.sementara itu, untuk di lokasi kebakaran, dedi mengatakan, polri melakukan pengamanan terhadap lokasi kebakaran baik di depo plumpang, maupun lokasi rumah warga terdampak yang ditinggal mengungsi.polri juga mendirikan posko tanggap darurat kebakaran secara terpadu dan pengaduan orang hilang di depan halaman koramil koja. \"mendirikan dapur umum di pos polisi oleh sat brimobda pmj dan membantu posko pengungaian bpbd,\" katanya.pilihan editor:profil depo pertamina plumpang, pemasok 20 persen pasokan bbm di seluruh indonesia\n",
      "Original: info nasional - ketua mpr ri sekaligus ketua umum ikatan motor indonesia (imi) dan wakil ketua umum partai golkar bambang soesatyo diangkat sebagai ketua dewan pembina harley davidson club indonesia (hdci) periode 2023-2028.bamsoet berharap hdci akan tetap konsisten mempertahankan citra positif yang telah dibangun. sehingga, dapat menginspirasi klub-klub otomotif lainnya untuk memberikan kontribusi terbaik bagi kehidupan sosial kemasyarakatan.\"selamat kepada sahabat saya ahmad sahroni yang telah terpilih sebagai ketua umum hdci periode 2023-2028 pada musyawarah nasional luar biasa tanggal 27-28 januari 2023 di bali,\" kata bamsoet saat membuka rapat kerja nasional (rakernas) hdci dan pelantikan pengurus pusat hdci periode 2023-2028 di semarang, jumat malam, 3 maret 2023.bamsoet yakin dan percaya dengan pengalaman dan wawasan organisasi yang luas, kemampuan membangun networking yang handal, serta kecintaan yang tulus pada dunia otomotif, ahmad sahroni memiliki segala kualifikasi. \"dan kompetensi yang dibutuhkan untuk memimpin dan memajukan organisasi hdci,\" ujar bamsoet.hadir antara lain ketua umum hdci ahmad sahroni, kakorlantas polri irjen pol. firman santyabudi, wakapolda jawa tengah brigjen pol. abiyoso seno aji, dirjen administrasi hukum umum kemenkumham cahyo rahadian muzhar, kajati dki jakarta reda manthovani dan kajati jawa tengah 1 made suarnawan.ketua dpr ri ke-20 dan mantan ketua komisi 3 dpr ri bidang hukum, ham, dan keamanan ini menjelaskan, sejak didirikan pada 28 mei 1990, hdci terus tumbuh dan berkembang hingga memiliki puluhan ribu anggota yang tersebar di seluruh wilayah nusantara. namun, hdci 'besar' bukan hanya karena jumlah anggotanya.tapi, karena kiprah dan kontribusinya dalam kehidupan masyarakat, khususnya melalui berbagai aksi sosial kemanusiaan yang diprakarsainya. \"pada berbagai event yang diselenggarakan oleh hdci, hampir selalu dibarengi dengan agenda bakti sosial. bahkan pada acara pelantikan pengurus dan rakernas kali ini, juga disertai dengan pemberian tanda kasih bagi ribuan anak yatim,\" kata bamsoet.wakil ketua umum partai golkar dan kepala badan hubungan penegakan hukum, pertahanan dan keamanan kadin indonesia ini mengatakan, kiprah positif hdci tidak hanya dirasakan dari maraknya berbagai aksi sosial yang dilakukan. tetapi, juga pada keberpihakan dan dukungan hdci untuk memajukan perekonomian masyarakat.\"salah satunya melalui implementasi konsep sport automotive tourism yang menyatukan aktivitas otomotif dengan upaya memajukan sektor pariwisata, sehingga dapat mendorong geliat perekonomian rakyat, khususnya para pelaku umkm di daerah,\" ujar bamsoet.ketua umum pengurus besar keluarga olahraga tarung derajat dan wakil ketua umum pemuda pancasila menilai kiprah dan kontribusi hdci yang telah dilakukan memiliki makna mendalam, khususnya ditengah masih adanya pandangan negatif dari sebagian masyarakat terhadap keberadaan klub motor besar. eksistensi klub motor besar dipandang sebagai simbol eksklusivisme yang telah membentuk sekat dan kelas sosial yang membentangkan jarak dengan kelompok masyarakat lainnya.\"karena itu, saya sangat mengapresiasi komitmen ahmad sahroni beserta segenap jajaran pengurus hdci, untuk menjadikan organisasi hdci sebagai pelayan, pelindung, dan pemersatu,\" ujarnya.menurutnya, komitmen ini mengisyaratkan adanya semangat inklusivitas, untuk merangkul semua kalangan. \"sekaligus jiwa solidaritas yang mengedepankan semangat kekeluargaan dan kebersamaan\". (*)\n",
      "Tokens: ['▁info', '▁nasional', '▁-', '▁ketua', '▁mp', 'r', '▁ri', '▁sekaligus', '▁ketua', '▁umum', '▁i', 'katan', '▁motor', '▁indonesia', '▁(', 'imi', ')', '▁dan', '▁wakil', '▁ketua', '▁umum', '▁partai', '▁gol', 'kar', '▁ba', 'mbang', '▁so', 'es', 'at', 'yo', '▁di', 'angkat', '▁sebagai', '▁ketua', '▁de', 'wan', '▁pemb', 'ina', '▁har', 'ley', '▁da', 'vid', 'son', '▁club', '▁indonesia', '▁(', 'hd', 'ci', ')', '▁periode', '▁2023', '-20', '28', '.', 'bam', 'so', 'et', '▁berharap', '▁hd', 'ci', '▁akan', '▁tetap', '▁konsisten', '▁mempertahankan', '▁ci', 'tra', '▁positif', '▁yang', '▁telah', '▁dibangun', '.', '▁sehingga', ',', '▁dapat', '▁meng', 'in', 'spira', 'si', '▁klub', '-', 'klub', '▁oto', 'motif', '▁lainnya', '▁untuk', '▁memberikan', '▁kontribu', 'si', '▁terbaik', '▁bagi', '▁kehidupan', '▁sosial', '▁ke', 'masyarakat', 'an', '.\"', 'sel', 'amat', '▁kepada', '▁sahabat', '▁saya', '▁ah', 'mad', '▁sah', 'roni', '▁yang', '▁telah', '▁terpilih', '▁sebagai', '▁ketua', '▁umum', '▁hd', 'ci', '▁periode', '▁2023', '-20', '28', '▁pada', '▁mus', 'ya', 'wa', 'rah', '▁nasional', '▁luar', '▁biasa', '▁tanggal', '▁27', '-28', '▁januari', '▁2023', '▁di', '▁bali', ',', '\"', '▁kata', '▁bam', 'so', 'et', '▁saat', '▁membuka', '▁rapat', '▁kerja', '▁nasional', '▁(', 'rak', 'ernas', ')', '▁hd', 'ci', '▁dan', '▁pelan', 'tikan', '▁pengurus', '▁pusat', '▁hd', 'ci', '▁periode', '▁2023', '-20', '28', '▁di', '▁sem', 'a', 'rang', ',', '▁ju', 'mat', '▁malam', ',', '▁3', '▁mare', 't', '▁2023', '.', 'bam', 'so', 'et', '▁yakin', '▁dan', '▁percaya', '▁dengan', '▁pengalaman', '▁dan', '▁wa', 'wasan', '▁organisasi', '▁yang', '▁luas', ',', '▁kemampuan', '▁membangun', '▁networking', '▁yang', '▁hand', 'al', ',', '▁serta', '▁ke', 'cinta', 'an', '▁yang', '▁tulu', 's', '▁pada', '▁dunia', '▁oto', 'motif', ',', '▁ah', 'mad', '▁sah', 'roni', '▁memiliki', '▁segala', '▁kualifik', 'asi', '.', '▁\"', 'dan', '▁kompetens', 'i', '▁yang', '▁dibutuhkan', '▁untuk', '▁memimpin', '▁dan', '▁mema', 'ju', 'kan', '▁organisasi', '▁hd', 'ci', ',', '\"', '▁ujar', '▁bam', 'so', 'et', '.', 'ha', 'dir', '▁antara', '▁lain', '▁ketua', '▁umum', '▁hd', 'ci', '▁ah', 'mad', '▁sah', 'roni', ',', '▁kakor', 'lanta', 's', '▁pol', 'ri', '▁ir', 'jen', '▁pol', '.', '▁firma', 'n', '▁sant', 'ya', 'bud', 'i', ',', '▁waka', 'pol', 'da', '▁ja', 'wa', '▁tengah', '▁brig', 'jen', '▁pol', '.', '▁a', 'biy', 'oso', '▁se', 'no', '▁a', 'ji', ',', '▁dir', 'jen', '▁administra', 'si', '▁hukum', '▁umum', '▁ke', 'men', 'kum', 'ham', '▁ca', 'hy', 'o', '▁raha', 'dian', '▁muz', 'har', ',', '▁kaj', 'ati', '▁d', 'ki', '▁ja', 'karta', '▁reda', '▁man', 'tho', 'vani', '▁dan', '▁kaj', 'ati', '▁ja', 'wa', '▁tengah', '▁1', '▁made', '▁su', 'arna', 'wan', '.', 'ke', 'tua', '▁d', 'pr', '▁ri', '▁ke', '-20', '▁dan', '▁mantan', '▁ketua', '▁komisi', '▁3', '▁d', 'pr', '▁ri', '▁bidang', '▁hukum', ',', '▁ham', ',', '▁dan', '▁keamanan', '▁ini', '▁menjelaskan', ',', '▁sejak', '▁didirikan', '▁pada', '▁28', '▁mei', '▁1990', ',', '▁hd', 'ci', '▁terus', '▁tumbuh', '▁dan', '▁berkembang', '▁hingga', '▁memiliki', '▁puluhan', '▁ribu', '▁anggota', '▁yang', '▁tersebar', '▁di', '▁seluruh', '▁wilayah', '▁nu', 's', 'antara', '.', '▁namun', ',', '▁hd', 'ci', \"▁'\", 'besar', \"'\", '▁bukan', '▁hanya', '▁karena', '▁jumlah', '▁anggota', 'nya', '.', 'tapi', ',', '▁karena', '▁kip', 'rah', '▁dan', '▁kontribu', 'sinya', '▁dalam', '▁kehidupan', '▁masyarakat', ',', '▁khususnya', '▁melalui', '▁berbagai', '▁aksi', '▁sosial', '▁kemanusiaan', '▁yang', '▁di', 'prak', 'arsa', 'inya', '.', '▁\"', 'pada', '▁berbagai', '▁event', '▁yang', '▁diselenggarakan', '▁oleh', '▁hd', 'ci', ',', '▁hampir', '▁selalu', '▁di', 'baren', 'gi', '▁dengan', '▁agenda', '▁bak', 'ti', '▁sosial', '.', '▁bahkan', '▁pada', '▁acara', '▁pelan', 'tikan', '▁pengurus', '▁dan', '▁rak', 'ernas', '▁kali', '▁ini', ',', '▁juga', '▁disertai', '▁dengan', '▁pemberian', '▁tanda', '▁kasih', '▁bagi', '▁ribuan', '▁anak', '▁ya', 'tim', ',', '\"', '▁kata', '▁bam', 'so', 'et', '.', 'wakil', '▁ketua', '▁umum', '▁partai', '▁gol', 'kar', '▁dan', '▁kepala', '▁badan', '▁hubungan', '▁pe', 'nega', 'kan', '▁hukum', ',', '▁pertahanan', '▁dan', '▁keamanan', '▁kad', 'in', '▁indonesia', '▁ini', '▁mengatakan', ',', '▁kip', 'rah', '▁positif', '▁hd', 'ci', '▁tidak', '▁hanya', '▁dirasakan', '▁dari', '▁mara', 'knya', '▁berbagai', '▁aksi', '▁sosial', '▁yang', '▁dilakukan', '.', '▁tetapi', ',', '▁juga', '▁pada', '▁ke', 'ber', 'pihak', 'an', '▁dan', '▁dukungan', '▁hd', 'ci', '▁untuk', '▁mema', 'ju', 'kan', '▁perekonomian', '▁masyarakat', '.\"', 'salah', '▁satunya', '▁melalui', '▁implementa', 'si', '▁konsep', '▁sport', '▁auto', 'motiv', 'e', '▁', 'tourism', '▁yang', '▁me', 'nya', 'tukan', '▁aktivitas', '▁oto', 'motif', '▁dengan', '▁upaya', '▁mema', 'ju', 'kan', '▁sektor', '▁pariwisata', ',', '▁sehingga', '▁dapat', '▁mendorong', '▁geli', 'at', '▁perekonomian', '▁rakyat', ',', '▁khususnya', '▁para', '▁pelaku', '▁um', 'km', '▁di', '▁daerah', ',', '\"', '▁ujar', '▁bam', 'so', 'et', '.', 'ke', 'tua', '▁umum', '▁pengurus', '▁besar', '▁keluarga', '▁olahraga', '▁tar', 'ung', '▁der', 'ajat', '▁dan', '▁wakil', '▁ketua', '▁umum', '▁pemuda', '▁pan', 'ca', 'sila', '▁menilai', '▁kip', 'rah', '▁dan', '▁kontribu', 'si', '▁hd', 'ci', '▁yang', '▁telah', '▁dilakukan', '▁memiliki', '▁makna', '▁mendalam', ',', '▁khususnya', '▁di', 'tengah', '▁masih', '▁adanya', '▁pandangan', '▁negatif', '▁dari', '▁sebagian', '▁masyarakat', '▁terhadap', '▁keberadaan', '▁klub', '▁motor', '▁besar', '.', '▁eksistens', 'i', '▁klub', '▁motor', '▁besar', '▁dipandang', '▁sebagai', '▁simbol', '▁eksklusiv', 'isme', '▁yang', '▁telah', '▁membentuk', '▁se', 'kat', '▁dan', '▁kelas', '▁sosial', '▁yang', '▁membe', 'nt', 'angkan', '▁jarak', '▁dengan', '▁kelompok', '▁masyarakat', '▁lainnya', '.\"', 'karena', '▁itu', ',', '▁saya', '▁sangat', '▁menga', 'pres', 'i', 'asi', '▁komitmen', '▁ah', 'mad', '▁sah', 'roni', '▁beserta', '▁se', 'gen', 'ap', '▁ja', 'jaran', '▁pengurus', '▁hd', 'ci', ',', '▁untuk', '▁menjadikan', '▁organisasi', '▁hd', 'ci', '▁sebagai', '▁pe', 'layan', ',', '▁peli', 'ndung', ',', '▁dan', '▁pe', 'mer', 'satu', ',', '\"', '▁ujarnya', '.', 'men', 'urut', 'nya', ',', '▁komitmen', '▁ini', '▁mengi', 'syarat', 'kan', '▁adanya', '▁semangat', '▁in', 'klusi', 'vita', 's', ',', '▁untuk', '▁mera', 'ngkul', '▁semua', '▁kalangan', '.', '▁\"', 'se', 'kali', 'gus', '▁jiwa', '▁solidari', 'tas', '▁yang', '▁menge', 'depan', 'kan', '▁semangat', '▁ke', 'kel', 'uar', 'gaan', '▁dan', '▁ke', 'ber', 's', 'amaan', '\".', '▁(*)']\n",
      "Reconstructed: info nasional - ketua mpr ri sekaligus ketua umum ikatan motor indonesia (imi) dan wakil ketua umum partai golkar bambang soesatyo diangkat sebagai ketua dewan pembina harley davidson club indonesia (hdci) periode 2023-2028.bamsoet berharap hdci akan tetap konsisten mempertahankan citra positif yang telah dibangun. sehingga, dapat menginspirasi klub-klub otomotif lainnya untuk memberikan kontribusi terbaik bagi kehidupan sosial kemasyarakatan.\"selamat kepada sahabat saya ahmad sahroni yang telah terpilih sebagai ketua umum hdci periode 2023-2028 pada musyawarah nasional luar biasa tanggal 27-28 januari 2023 di bali,\" kata bamsoet saat membuka rapat kerja nasional (rakernas) hdci dan pelantikan pengurus pusat hdci periode 2023-2028 di semarang, jumat malam, 3 maret 2023.bamsoet yakin dan percaya dengan pengalaman dan wawasan organisasi yang luas, kemampuan membangun networking yang handal, serta kecintaan yang tulus pada dunia otomotif, ahmad sahroni memiliki segala kualifikasi. \"dan kompetensi yang dibutuhkan untuk memimpin dan memajukan organisasi hdci,\" ujar bamsoet.hadir antara lain ketua umum hdci ahmad sahroni, kakorlantas polri irjen pol. firman santyabudi, wakapolda jawa tengah brigjen pol. abiyoso seno aji, dirjen administrasi hukum umum kemenkumham cahyo rahadian muzhar, kajati dki jakarta reda manthovani dan kajati jawa tengah 1 made suarnawan.ketua dpr ri ke-20 dan mantan ketua komisi 3 dpr ri bidang hukum, ham, dan keamanan ini menjelaskan, sejak didirikan pada 28 mei 1990, hdci terus tumbuh dan berkembang hingga memiliki puluhan ribu anggota yang tersebar di seluruh wilayah nusantara. namun, hdci 'besar' bukan hanya karena jumlah anggotanya.tapi, karena kiprah dan kontribusinya dalam kehidupan masyarakat, khususnya melalui berbagai aksi sosial kemanusiaan yang diprakarsainya. \"pada berbagai event yang diselenggarakan oleh hdci, hampir selalu dibarengi dengan agenda bakti sosial. bahkan pada acara pelantikan pengurus dan rakernas kali ini, juga disertai dengan pemberian tanda kasih bagi ribuan anak yatim,\" kata bamsoet.wakil ketua umum partai golkar dan kepala badan hubungan penegakan hukum, pertahanan dan keamanan kadin indonesia ini mengatakan, kiprah positif hdci tidak hanya dirasakan dari maraknya berbagai aksi sosial yang dilakukan. tetapi, juga pada keberpihakan dan dukungan hdci untuk memajukan perekonomian masyarakat.\"salah satunya melalui implementasi konsep sport automotive tourism yang menyatukan aktivitas otomotif dengan upaya memajukan sektor pariwisata, sehingga dapat mendorong geliat perekonomian rakyat, khususnya para pelaku umkm di daerah,\" ujar bamsoet.ketua umum pengurus besar keluarga olahraga tarung derajat dan wakil ketua umum pemuda pancasila menilai kiprah dan kontribusi hdci yang telah dilakukan memiliki makna mendalam, khususnya ditengah masih adanya pandangan negatif dari sebagian masyarakat terhadap keberadaan klub motor besar. eksistensi klub motor besar dipandang sebagai simbol eksklusivisme yang telah membentuk sekat dan kelas sosial yang membentangkan jarak dengan kelompok masyarakat lainnya.\"karena itu, saya sangat mengapresiasi komitmen ahmad sahroni beserta segenap jajaran pengurus hdci, untuk menjadikan organisasi hdci sebagai pelayan, pelindung, dan pemersatu,\" ujarnya.menurutnya, komitmen ini mengisyaratkan adanya semangat inklusivitas, untuk merangkul semua kalangan. \"sekaligus jiwa solidaritas yang mengedepankan semangat kekeluargaan dan kebersamaan\". (*)\n"
     ]
    }
   ],
   "source": [
    "for column in columns_to_tokenize:\n",
    "    for text in df[column].head():  \n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        reconstructed = tokenizer.convert_tokens_to_string(tokens)\n",
    "        print(f\"Original: {text}\")\n",
    "        print(f\"Tokens: {tokens}\")\n",
    "        print(f\"Reconstructed: {reconstructed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c001dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: title_token_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 36524/36524 [1:03:52<00:00,  9.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: content_token_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 36524/36524 [6:48:54<00:00,  1.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been successfully added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenized data\n",
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df = pd.read_csv(tokenized_file_path)\n",
    "\n",
    "# Columns to process\n",
    "columns_to_tokenize = ['title_token_ids', 'content_token_ids']\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Embedding extraction function with progress bar\n",
    "def get_embeddings_from_token_ids(token_ids_column):\n",
    "    embeddings = []\n",
    "    \n",
    "    # Wrap the loop with tqdm to display a progress bar\n",
    "    for token_ids in tqdm(token_ids_column, desc=\"Generating embeddings\"):\n",
    "        if pd.notnull(token_ids) and len(token_ids) > 0: \n",
    "            token_ids = eval(token_ids)  # Convert stringified list back to list of integers\n",
    "            \n",
    "            inputs = torch.tensor([token_ids])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "                # Compute the mean of hidden states across the sequence\n",
    "                embedding = last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "                embeddings.append(embedding)\n",
    "        else:\n",
    "            embeddings.append([])  # Append an empty list if token IDs are missing\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Process columns with progress bars\n",
    "for column in columns_to_tokenize:\n",
    "    print(f\"Processing column: {column}\")\n",
    "    df[f\"{column}_embeddings\"] = get_embeddings_from_token_ids(df[column])\n",
    "\n",
    "# Save the updated DataFrame\n",
    "tokenized_with_embeddings_file_path = 'tokenized_with_embeddings.csv'\n",
    "df.to_csv(tokenized_with_embeddings_file_path, index=False)\n",
    "\n",
    "print(\"Embeddings have been successfully added to the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de346abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbcc20e9d9040b5bb6d4a952b93040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adiat\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7350ec3e55f4f618749747000f9f2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bca6d3fab54c74b8ac1e32e5e36e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48961dc8af204fbfb48fd67ba825c14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd86f37eea5489aa55df9e9a3cce25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfe5e3ca0d94ac7b71bd9488ae84b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5ffb9540b64c31aad5b1b2d4d5099b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6687468f28848f9b5c632cfff11147a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f8179d6be40e585acfe8d07a2d661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9246c7f50b254a89891874508c7e571a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c608e082bd4a659cb31858c417777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36964, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "df_merge['combined_text'] = df_merge['title'] + \" \" + df_merge['content'] + \" \" + df_merge['summary']\n",
    "df_merge['combined_text'] = df_merge['combined_text'].apply(lambda x: str(x) if pd.notna(x) else \"\")\n",
    "\n",
    "\n",
    "text_embeddings = model.encode(df_merge['combined_text'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "np.save('embeddings.npy', text_embeddings)\n",
    "\n",
    "print(text_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"Kalo mo pake masukin API key kalian bang\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a660bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge['input'] = df_merge.apply(\n",
    "#     lambda x: f\"title: {' '.join(x['title_tokens'])} content: {' '.join(x['content_tokens'])} summary: {' '.join(x['summary_tokens'])}\", axis=1\n",
    "# )\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"input\"],\n",
    "#     template=\"Analyze the following news and determine its authenticity: {input}\"\n",
    "# )\n",
    "\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# def analyze_row(row):\n",
    "#     try:\n",
    "#         return llm_chain.run({\"input\": row['input']})\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row: {e}\")\n",
    "#         return \"Error\"\n",
    "\n",
    "# batch_size = 200\n",
    "\n",
    "# for start in range(0, len(df_merge), batch_size):\n",
    "#     batch = df_merge.iloc[start:start+batch_size]\n",
    "#     batch['predicted_label'] = batch.apply(analyze_row, axis=1)\n",
    "    \n",
    "#     batch.to_csv(f\"llm_predictions_batch_{start}.csv\", index=False)\n",
    "#     print(f\"Processed batch {start}-{start + batch_size - 1}\")\n",
    "\n",
    "# print(\"Batch processing completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9574fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index contains 36964 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings.npy\").astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  \n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Index contains {index.ntotal} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index, docstore, and mappings saved.\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings.npy\").astype('float32')\n",
    "documents = df_merge['content'].tolist()  # Document content\n",
    "metadata = [{\"title\": row['title'], \"summary\": row['summary']} for _, row in df_merge.iterrows()]  # Metadata for documents\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "docstore_data = {str(i): {\"page_content\": documents[i], \"metadata\": metadata[i]} for i in range(len(documents))}\n",
    "docstore = InMemoryDocstore(docstore_data)\n",
    "\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(documents))}\n",
    "\n",
    "faiss.write_index(index, \"faiss_index.index.faiss\")\n",
    "\n",
    "with open(\"docstore.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docstore, f)\n",
    "with open(\"index_to_docstore_id.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index_to_docstore_id, f)\n",
    "\n",
    "print(\"FAISS index, docstore, and mappings saved.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e19873f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd151d3441d407db90db79b34c88f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adiat\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0058a8bee51426c887a14ef4be1b469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050a8fda62d741bc9f45989faae8c4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e508cced2c5c463dba49b2a2695550ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3288c49e894c898a529305d806a033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar documents:\n",
      "Another document about machine learning.\n",
      "This is a document about AI.\n",
      "\n",
      "Another document about machine learning.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "documents = []\n",
    "with open(\"documents.txt\", \"r\") as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "embeddings = np.load(\"document_embeddings.npy\")\n",
    "index = faiss.read_index(\"document_index.index\")\n",
    "\n",
    "def retrieve_similar_documents(query, top_k=3):\n",
    "    query_embedding = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        query_output = model(**query_embedding)\n",
    "    query_embedding = query_output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    D, I = index.search(query_embedding, top_k)  \n",
    "    similar_documents = [documents[idx] for idx in I[0]]\n",
    "    return similar_documents\n",
    "\n",
    "query = \"AI technology is advancing rapidly, how is it affecting jobs?\"\n",
    "similar_docs = retrieve_similar_documents(query)\n",
    "\n",
    "print(\"Top 3 similar documents:\")\n",
    "for doc in similar_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9abd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cfc325266e431eb288c546a9fbb9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adiat\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d04fbd7dec4f3bb0cbea0bd41b4bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190f807e27fc41f285f10f3f680197b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588049a07ff419dbcf11d564c2eb1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f61c3f9dc1c48a5b11414d6513e7888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Result: [{'label': 'LABEL_0', 'score': 0.34845447540283203}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake_news_classifier = pipeline(\"text-classification\", model=\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "def integrate_for_fake_news_detection(query, similar_documents):\n",
    "    context = \" \".join(similar_documents)  \n",
    "    combined_input = f\"Query: {query} Context: {context}\"\n",
    "\n",
    "    result = fake_news_classifier(combined_input)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = integrate_for_fake_news_detection(query, similar_docs)\n",
    "print(\"Fake News Detection Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef15f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Replace NaN values in 'content' column with empty strings\n",
    "df['content'] = df['content'].fillna('')\n",
    "\n",
    "# Initialize the IndoBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "\n",
    "\n",
    "def preprocess_data(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)  \n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply the preprocessing to the 'content' or 'title' column\n",
    "df['inputs'] = df['content'].apply(preprocess_data)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['inputs'].tolist(), df['Status'].tolist(), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef689205",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 18 at dim 1 (got 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m test_content_tokens \u001b[38;5;241m=\u001b[39m test_hoax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_token_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28meval\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Convert token lists into PyTorch tensors\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m train_title_tokens_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_title_tokens)\n\u001b[0;32m     27\u001b[0m train_content_tokens_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_content_tokens)\n\u001b[0;32m     29\u001b[0m test_title_tokens_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(test_title_tokens)\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 18 at dim 1 (got 20)"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# max_length = 128\n",
    "\n",
    "# # Load the datasets\n",
    "# df_hoax = pd.read_csv('tokenized_data_hoax.csv')\n",
    "# df = pd.read_csv('tokenized_data.csv')\n",
    "\n",
    "# # Ensure the 'Status' column is in an appropriate format (e.g., 0 and 1 for binary classification)\n",
    "# df_hoax['Status'] = df_hoax['Status'].apply(lambda x: 1 if x == 'fake' else 0)  # Assuming 'fake' is the hoax label\n",
    "# df['Status'] = df['Status'].apply(lambda x: 1 if x == 'fake' else 0)  # Adjust if needed\n",
    "\n",
    "# # Split into train and test sets (using df_hoax as an example)\n",
    "# train_hoax, test_hoax = train_test_split(df_hoax, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Use the tokenized columns (title_token_ids and content_token_ids) directly\n",
    "# train_title_tokens = train_hoax['title_token_ids'].apply(eval).tolist()  \n",
    "# train_content_tokens = train_hoax['content_token_ids'].apply(eval).tolist()\n",
    "\n",
    "# test_title_tokens = test_hoax['title_token_ids'].apply(eval).tolist()\n",
    "# test_content_tokens = test_hoax['content_token_ids'].apply(eval).tolist()\n",
    "\n",
    "# # Convert token lists into PyTorch tensors\n",
    "# train_title_tokens_tensor = torch.tensor(train_title_tokens)\n",
    "# train_content_tokens_tensor = torch.tensor(train_content_tokens)\n",
    "\n",
    "# test_title_tokens_tensor = torch.tensor(test_title_tokens)\n",
    "# test_content_tokens_tensor = torch.tensor(test_content_tokens)\n",
    "\n",
    "# # Labels as tensors\n",
    "# train_labels = torch.tensor(train_hoax['Status'].values)\n",
    "# test_labels = torch.tensor(test_hoax['Status'].values)\n",
    "\n",
    "# train_inputs = torch.cat((train_title_tokens_tensor, train_content_tokens_tensor), dim=1)\n",
    "# test_inputs = torch.cat((test_title_tokens_tensor, test_content_tokens_tensor), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00d14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_hoax = pd.read_csv('tokenized_data_hoax.csv')\n",
    "df = pd.read_csv('tokenized_data.csv')\n",
    "\n",
    "# Ensure the 'Status' column is in an appropriate format (e.g., 0 and 1 for binary classification)\n",
    "df_hoax['Status'] = df_hoax['Status'].apply(lambda x: 1 if x == 'fake' else 0)  # Assuming 'fake' is the hoax label\n",
    "df['Status'] = df['Status'].apply(lambda x: 1 if x == 'fake' else 0)  # Adjust if needed\n",
    "\n",
    "# Split into train and test sets (using df_hoax as an example)\n",
    "train_hoax, test_hoax = train_test_split(df_hoax, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the tokenized columns (title_token_ids and content_token_ids) directly\n",
    "train_title_tokens = train_hoax['title_token_ids'].apply(eval).tolist()  \n",
    "train_content_tokens = train_hoax['content_token_ids'].apply(eval).tolist()\n",
    "\n",
    "test_title_tokens = test_hoax['title_token_ids'].apply(eval).tolist()\n",
    "test_content_tokens = test_hoax['content_token_ids'].apply(eval).tolist()\n",
    "\n",
    "# Define maximum lengths for padding\n",
    "max_title_length = 50  # Adjust based on your data\n",
    "max_content_length = 200  # Adjust based on your data\n",
    "\n",
    "# Function to pad or truncate sequences\n",
    "def pad_or_truncate(tokens, max_length):\n",
    "    if len(tokens) > max_length:\n",
    "        return tokens[:max_length]\n",
    "    else:\n",
    "        return tokens + [0] * (max_length - len(tokens))\n",
    "\n",
    "# Apply padding/truncation\n",
    "train_title_tokens_padded = [pad_or_truncate(tokens, max_title_length) for tokens in train_title_tokens]\n",
    "train_content_tokens_padded = [pad_or_truncate(tokens, max_content_length) for tokens in train_content_tokens]\n",
    "\n",
    "test_title_tokens_padded = [pad_or_truncate(tokens, max_title_length) for tokens in test_title_tokens]\n",
    "test_content_tokens_padded = [pad_or_truncate(tokens, max_content_length) for tokens in test_content_tokens]\n",
    "\n",
    "# Convert token lists into PyTorch tensors\n",
    "train_title_tokens_tensor = torch.tensor(train_title_tokens_padded)\n",
    "train_content_tokens_tensor = torch.tensor(train_content_tokens_padded)\n",
    "\n",
    "test_title_tokens_tensor = torch.tensor(test_title_tokens_padded)\n",
    "test_content_tokens_tensor = torch.tensor(test_content_tokens_padded)\n",
    "\n",
    "# Labels as tensors\n",
    "train_labels = torch.tensor(train_hoax['Status'].values)\n",
    "test_labels = torch.tensor(test_hoax['Status'].values)\n",
    "\n",
    "# Concatenate title and content tensors along the sequence dimension\n",
    "train_inputs = torch.cat((train_title_tokens_tensor, train_content_tokens_tensor), dim=1)\n",
    "test_inputs = torch.cat((test_title_tokens_tensor, test_content_tokens_tensor), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the pre-trained IndoBERT model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindobenchmark/indobert-base-p1\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      7\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      8\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      9\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m     10\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,        \n\u001b[0;32m     11\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     13\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m   \n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Trainer definition\u001b[39;00m\n\u001b[0;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1773\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[1;32mc:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2299\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2298\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:60\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\adiat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2172\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   2171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2173\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2175\u001b[0m         )\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained IndoBERT model\n",
    "model = BertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p1', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",        \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True   \n",
    ")\n",
    "\n",
    "# Trainer definition\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encodings,\n",
    "    eval_dataset=test_encodings,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model (kalau udh bagus)\n",
    "# model.save_pretrained('./fake_news_model')\n",
    "# tokenizer.save_pretrained('./fake_news_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f14453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "predictions = trainer.predict(test_encodings)\n",
    "pred_labels = torch.argmax(predictions.predictions, axis=-1).item()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Compute the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, pred_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the fine-tuned model\n",
    "# model = BertForSequenceClassification.from_pretrained('./fake_news_model')\n",
    "# tokenizer = BertTokenizer.from_pretrained('./fake_news_model')\n",
    "\n",
    "# # Sample query\n",
    "# query = \"Apakah berita ini benar atau hoax?\"\n",
    "# inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "\n",
    "# # Make prediction\n",
    "# outputs = model(**inputs)\n",
    "# logits = outputs.logits\n",
    "# predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# print(f\"Predicted label: {predicted_label}\")\n",
    "# Untuk kalau udh dapat model yang bagus \n",
    "# can use it to make predictions on new data inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7039e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
