{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f301c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f962fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Depo Plumpang Terbakar, Anggota DPR Minta Pert...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698528/depo-pl...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...</td>\n",
       "      <td>2023-03-04 06:18:13+00</td>\n",
       "      <td>[-0.01590039,-0.034130897,0.005732614,-0.01853...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Anggota Komisi VII DPR RI Rofik Hananto menyay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698522/jokowi-...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...</td>\n",
       "      <td>2023-03-04 06:04:38+00</td>\n",
       "      <td>[-0.017608976,-0.021786924,0.01547983,-0.00932...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Presiden Joko Widodo telah memerintahkan Wakil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>tempo</td>\n",
       "      <td>HNW Mendukung Jamaah Umroh First Travel Dapatk...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698527/hnw-men...</td>\n",
       "      <td>INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...</td>\n",
       "      <td>2023-03-04 06:18:04+00</td>\n",
       "      <td>[0.00841488,-0.023665192,0.006762431,-0.013723...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698540/tim-dok...</td>\n",
       "      <td>TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...</td>\n",
       "      <td>2023-03-04 06:44:10+00</td>\n",
       "      <td>[-0.012671886,-0.0039057182,0.019575326,-0.016...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Tim Kedokteran dan Kesehatan (Dokkes) Polri te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>tempo</td>\n",
       "      <td>Bamsoet Ajak Komunitas Otomotif Kembangkan Per...</td>\n",
       "      <td>https://statik.tempo.co/data/2023/03/04/id_118...</td>\n",
       "      <td>https://nasional.tempo.co/read/1698536/bamsoet...</td>\n",
       "      <td>INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...</td>\n",
       "      <td>2023-03-04 06:38:57+00</td>\n",
       "      <td>[-0.015486176,-0.0125719,-0.0122843925,-0.0343...</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>2023-03-04 07:03:39.039332</td>\n",
       "      <td>Ketua MPR RI Bambang Soesatyo telah diangkat s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id source                                              title  \\\n",
       "0  83  tempo  Depo Plumpang Terbakar, Anggota DPR Minta Pert...   \n",
       "1  84  tempo  Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...   \n",
       "2  85  tempo  HNW Mendukung Jamaah Umroh First Travel Dapatk...   \n",
       "3  86  tempo  Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...   \n",
       "4  87  tempo  Bamsoet Ajak Komunitas Otomotif Kembangkan Per...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "1  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "2  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "3  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "4  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://nasional.tempo.co/read/1698528/depo-pl...   \n",
       "1  https://nasional.tempo.co/read/1698522/jokowi-...   \n",
       "2  https://nasional.tempo.co/read/1698527/hnw-men...   \n",
       "3  https://nasional.tempo.co/read/1698540/tim-dok...   \n",
       "4  https://nasional.tempo.co/read/1698536/bamsoet...   \n",
       "\n",
       "                                             content                    date  \\\n",
       "0  TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...  2023-03-04 06:18:13+00   \n",
       "1  TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...  2023-03-04 06:04:38+00   \n",
       "2  INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...  2023-03-04 06:18:04+00   \n",
       "3  TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...  2023-03-04 06:44:10+00   \n",
       "4  INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...  2023-03-04 06:38:57+00   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.01590039,-0.034130897,0.005732614,-0.01853...   \n",
       "1  [-0.017608976,-0.021786924,0.01547983,-0.00932...   \n",
       "2  [0.00841488,-0.023665192,0.006762431,-0.013723...   \n",
       "3  [-0.012671886,-0.0039057182,0.019575326,-0.016...   \n",
       "4  [-0.015486176,-0.0125719,-0.0122843925,-0.0343...   \n",
       "\n",
       "                   created_at                  updated_at  \\\n",
       "0  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "1  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "2  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "3  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "4  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
       "\n",
       "                                             summary  \n",
       "0  Anggota Komisi VII DPR RI Rofik Hananto menyay...  \n",
       "1  Presiden Joko Widodo telah memerintahkan Wakil...  \n",
       "2  Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...  \n",
       "3  Tim Kedokteran dan Kesehatan (Dokkes) Polri te...  \n",
       "4  Ketua MPR RI Bambang Soesatyo telah diangkat s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Initial Data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['image', 'url', 'embedding', 'created_at', 'updated_at']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(\"\\nAfter Dropping Unnecessary Columns:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rename_map = {\n",
    "    'id': 'record_id',\n",
    "    'source': 'news_source',\n",
    "    'date': 'publication_date'\n",
    "}\n",
    "df.rename(columns=columns_rename_map, inplace=True)\n",
    "print(\"\\nAfter Renaming Columns:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roman_to_int(roman):\n",
    "    roman_map = {\n",
    "        'I': 1, 'II': 2, 'III': 3, 'IV': 4, \n",
    "        'V': 5, 'VI': 6, 'VII': 7, 'VIII': 8, \n",
    "        'IX': 9, 'X': 10\n",
    "    }\n",
    "\n",
    "    return roman_map.get(roman, roman)\n",
    "\n",
    "\n",
    "def convert_roman_to_int(text):\n",
    "    def replace_roman(match):\n",
    "        roman_numeral = match.group(0)\n",
    "        return str(roman_to_int(roman_numeral))  # Convert Roman numeral to integer\n",
    "    \n",
    "\n",
    "    return re.sub(r'\\b(I|II|III|IV|V|VI|VII|VIII|IX|X)\\b', replace_roman, text)\n",
    "\n",
    "\n",
    "for col in ['title', 'content', 'summary']:\n",
    "    df[col] = df[col].apply(lambda x: convert_roman_to_int(x) if isinstance(x, str) else x)\n",
    "    df[col] = df[col].str.lower()  # Convert to lowercase\n",
    "\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Status'] = 1\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = 'cleaned_data.csv'\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned data saved to {cleaned_file_path}\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15ae402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized data saved to tokenized_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_file_path = 'cleaned_data.csv'\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "columns_to_tokenize = ['title', 'content', 'summary']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "for column in columns_to_tokenize:\n",
    "    df[f\"{column}_tokens\"] = df[column].apply(\n",
    "        lambda x: tokenizer.tokenize(x) if pd.notnull(x) else []\n",
    "    )\n",
    "    df[f\"{column}_token_ids\"] = df[column].apply(\n",
    "        lambda x: tokenizer.encode(x, truncation=True, max_length=512) if pd.notnull(x) else []\n",
    "    )\n",
    "\n",
    "tokenized_file_path = 'tokenized_data.csv'\n",
    "df.to_csv(tokenized_file_path, index=False)\n",
    "print(f\"Tokenized data saved to {tokenized_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc77503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = pd.read_csv('tokenized_data.csv')\n",
    "tokenized_df2= pd.read_csv('tokenized_data_hoax.csv')\n",
    "df_merge = pd.merge(tokenized_df, tokenized_df2, on=['record_id', 'content','Status','title','publication_date','title_token_ids','title_tokens','content_tokens','content_token_ids'], how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc25a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>news_source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>summary</th>\n",
       "      <th>Status</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_token_ids</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>content_token_ids</th>\n",
       "      <th>summary_tokens</th>\n",
       "      <th>summary_token_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36959</th>\n",
       "      <td>999287</td>\n",
       "      <td></td>\n",
       "      <td>: kpk dilarang membawa brimob bersenjata masuk...</td>\n",
       "      <td>kpk dilarang membawa brimob bersenjata masuk g...</td>\n",
       "      <td>17-jan-16</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[':', 'Ġk', 'p', 'k', 'Ġd', 'ilar', 'ang', 'Ġm...</td>\n",
       "      <td>[0, 35, 449, 642, 330, 385, 16813, 1097, 26012...</td>\n",
       "      <td>['k', 'p', 'k', 'Ġd', 'ilar', 'ang', 'Ġmem', '...</td>\n",
       "      <td>[0, 330, 642, 330, 385, 16813, 1097, 26012, 42...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>999472</td>\n",
       "      <td></td>\n",
       "      <td>foto pejabat keuangan dibawah palu arit</td>\n",
       "      <td>jangan mau dialihkan kepada pakaian adat… foku...</td>\n",
       "      <td>20-aug-20</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['f', 'oto', 'Ġpe', 'jab', 'at', 'Ġke', 'u', '...</td>\n",
       "      <td>[0, 506, 7087, 3723, 39805, 415, 7321, 257, 25...</td>\n",
       "      <td>['j', 'angan', 'Ġm', 'au', 'Ġdial', 'ih', 'kan...</td>\n",
       "      <td>[0, 267, 25750, 475, 1180, 11481, 4001, 11334,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>999501</td>\n",
       "      <td></td>\n",
       "      <td>gambar denny siregar musuh warga tasikmalaya d...</td>\n",
       "      <td>akhir nya bisa terkenal bang denny</td>\n",
       "      <td>17-aug-20</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['g', 'amb', 'ar', 'Ġd', 'enny', 'Ġs', 'ire', ...</td>\n",
       "      <td>[0, 571, 3146, 271, 385, 11867, 579, 1885, 627...</td>\n",
       "      <td>['akh', 'ir', 'Ġn', 'ya', 'Ġb', 'isa', 'Ġter',...</td>\n",
       "      <td>[0, 7352, 853, 295, 2636, 741, 6619, 8470, 694...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>999848</td>\n",
       "      <td></td>\n",
       "      <td>kaesang: bapak saya dengan kesederhaan bisa ni...</td>\n",
       "      <td>bapak saya dengan kesederhaan bisa nipu rakyat...</td>\n",
       "      <td>21-jul-20</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['ka', 'es', 'ang', ':', 'Ġb', 'ap', 'ak', 'Ġs...</td>\n",
       "      <td>[0, 2348, 293, 1097, 35, 741, 1115, 677, 224, ...</td>\n",
       "      <td>['b', 'ap', 'ak', 'Ġsay', 'a', 'Ġden', 'gan', ...</td>\n",
       "      <td>[0, 428, 1115, 677, 224, 102, 3069, 3494, 449,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>999860</td>\n",
       "      <td></td>\n",
       "      <td>laser dari termometer gun akan merusak struktu...</td>\n",
       "      <td>in: saya nolak. kalau anda mau periksa, bukan ...</td>\n",
       "      <td>20-jul-20</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>['l', 'aser', 'Ġd', 'ari', 'Ġterm', 'ometer', ...</td>\n",
       "      <td>[0, 462, 12425, 385, 1512, 1385, 12687, 1751, ...</td>\n",
       "      <td>['in', ':', 'Ġsay', 'a', 'Ġn', 'ol', 'ak', '.'...</td>\n",
       "      <td>[0, 179, 35, 224, 102, 295, 1168, 677, 4, 449,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_id news_source  \\\n",
       "36959     999287               \n",
       "36960     999472               \n",
       "36961     999501               \n",
       "36962     999848               \n",
       "36963     999860               \n",
       "\n",
       "                                                   title  \\\n",
       "36959  : kpk dilarang membawa brimob bersenjata masuk...   \n",
       "36960            foto pejabat keuangan dibawah palu arit   \n",
       "36961  gambar denny siregar musuh warga tasikmalaya d...   \n",
       "36962  kaesang: bapak saya dengan kesederhaan bisa ni...   \n",
       "36963  laser dari termometer gun akan merusak struktu...   \n",
       "\n",
       "                                                 content publication_date  \\\n",
       "36959  kpk dilarang membawa brimob bersenjata masuk g...        17-jan-16   \n",
       "36960  jangan mau dialihkan kepada pakaian adat… foku...        20-aug-20   \n",
       "36961                 akhir nya bisa terkenal bang denny        17-aug-20   \n",
       "36962  bapak saya dengan kesederhaan bisa nipu rakyat...        21-jul-20   \n",
       "36963  in: saya nolak. kalau anda mau periksa, bukan ...        20-jul-20   \n",
       "\n",
       "      summary  Status                                       title_tokens  \\\n",
       "36959               0  [':', 'Ġk', 'p', 'k', 'Ġd', 'ilar', 'ang', 'Ġm...   \n",
       "36960               0  ['f', 'oto', 'Ġpe', 'jab', 'at', 'Ġke', 'u', '...   \n",
       "36961               0  ['g', 'amb', 'ar', 'Ġd', 'enny', 'Ġs', 'ire', ...   \n",
       "36962               0  ['ka', 'es', 'ang', ':', 'Ġb', 'ap', 'ak', 'Ġs...   \n",
       "36963               0  ['l', 'aser', 'Ġd', 'ari', 'Ġterm', 'ometer', ...   \n",
       "\n",
       "                                         title_token_ids  \\\n",
       "36959  [0, 35, 449, 642, 330, 385, 16813, 1097, 26012...   \n",
       "36960  [0, 506, 7087, 3723, 39805, 415, 7321, 257, 25...   \n",
       "36961  [0, 571, 3146, 271, 385, 11867, 579, 1885, 627...   \n",
       "36962  [0, 2348, 293, 1097, 35, 741, 1115, 677, 224, ...   \n",
       "36963  [0, 462, 12425, 385, 1512, 1385, 12687, 1751, ...   \n",
       "\n",
       "                                          content_tokens  \\\n",
       "36959  ['k', 'p', 'k', 'Ġd', 'ilar', 'ang', 'Ġmem', '...   \n",
       "36960  ['j', 'angan', 'Ġm', 'au', 'Ġdial', 'ih', 'kan...   \n",
       "36961  ['akh', 'ir', 'Ġn', 'ya', 'Ġb', 'isa', 'Ġter',...   \n",
       "36962  ['b', 'ap', 'ak', 'Ġsay', 'a', 'Ġden', 'gan', ...   \n",
       "36963  ['in', ':', 'Ġsay', 'a', 'Ġn', 'ol', 'ak', '.'...   \n",
       "\n",
       "                                       content_token_ids summary_tokens  \\\n",
       "36959  [0, 330, 642, 330, 385, 16813, 1097, 26012, 42...                  \n",
       "36960  [0, 267, 25750, 475, 1180, 11481, 4001, 11334,...                  \n",
       "36961  [0, 7352, 853, 295, 2636, 741, 6619, 8470, 694...                  \n",
       "36962  [0, 428, 1115, 677, 224, 102, 3069, 3494, 449,...                  \n",
       "36963  [0, 179, 35, 224, 102, 295, 1168, 677, 4, 449,...                  \n",
       "\n",
       "      summary_token_ids  \n",
       "36959                    \n",
       "36960                    \n",
       "36961                    \n",
       "36962                    \n",
       "36963                    "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906d718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fix = ['summary', 'summary_tokens', 'summary_token_ids','news_source']\n",
    "df_merge[columns_to_fix] = df_merge[columns_to_fix].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a284ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_source\n",
      "<class 'str'>    36964\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_merge['news_source'].apply(type).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de346abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011d192ce53947899acd913b3936dab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36964, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "df_merge['combined_text'] = df_merge['title'] + \" \" + df_merge['content'] + \" \" + df_merge['summary']\n",
    "df_merge['combined_text'] = df_merge['combined_text'].apply(lambda x: str(x) if pd.notna(x) else \"\")\n",
    "\n",
    "\n",
    "text_embeddings = model.encode(df_merge['combined_text'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "np.save('embeddings.npy', text_embeddings)\n",
    "\n",
    "print(text_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"Kalo mo pake masukin API key kalian bang\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge['input'] = df_merge.apply(\n",
    "#     lambda x: f\"title: {' '.join(x['title_tokens'])} content: {' '.join(x['content_tokens'])} summary: {' '.join(x['summary_tokens'])}\", axis=1\n",
    "# )\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"input\"],\n",
    "#     template=\"Analyze the following news and determine its authenticity: {input}\"\n",
    "# )\n",
    "\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# def analyze_row(row):\n",
    "#     try:\n",
    "#         return llm_chain.run({\"input\": row['input']})\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row: {e}\")\n",
    "#         return \"Error\"\n",
    "\n",
    "# batch_size = 200\n",
    "\n",
    "# for start in range(0, len(df_merge), batch_size):\n",
    "#     batch = df_merge.iloc[start:start+batch_size]\n",
    "#     batch['predicted_label'] = batch.apply(analyze_row, axis=1)\n",
    "    \n",
    "#     batch.to_csv(f\"llm_predictions_batch_{start}.csv\", index=False)\n",
    "#     print(f\"Processed batch {start}-{start + batch_size - 1}\")\n",
    "\n",
    "# print(\"Batch processing completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9574fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index contains 36964 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings.npy\").astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  \n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Index contains {index.ntotal} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6eab8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index, docstore, and mappings saved.\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(\"embeddings.npy\").astype('float32')\n",
    "documents = df_merge['content'].tolist()  # Document content\n",
    "metadata = [{\"title\": row['title'], \"summary\": row['summary']} for _, row in df_merge.iterrows()]  # Metadata for documents\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "docstore_data = {str(i): {\"page_content\": documents[i], \"metadata\": metadata[i]} for i in range(len(documents))}\n",
    "docstore = InMemoryDocstore(docstore_data)\n",
    "\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(documents))}\n",
    "\n",
    "faiss.write_index(index, \"faiss_index.index.faiss\")\n",
    "\n",
    "with open(\"docstore.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docstore, f)\n",
    "with open(\"index_to_docstore_id.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index_to_docstore_id, f)\n",
    "\n",
    "print(\"FAISS index, docstore, and mappings saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19873f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar documents:\n",
      "Another document about machine learning.\n",
      "This is a document about AI.\n",
      "\n",
      "Another document about machine learning.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "documents = []\n",
    "with open(\"documents.txt\", \"r\") as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "embeddings = np.load(\"document_embeddings.npy\")\n",
    "index = faiss.read_index(\"document_index.index\")\n",
    "\n",
    "def retrieve_similar_documents(query, top_k=3):\n",
    "    query_embedding = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        query_output = model(**query_embedding)\n",
    "    query_embedding = query_output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    D, I = index.search(query_embedding, top_k)  \n",
    "    similar_documents = [documents[idx] for idx in I[0]]\n",
    "    return similar_documents\n",
    "\n",
    "query = \"AI technology is advancing rapidly, how is it affecting jobs?\"\n",
    "similar_docs = retrieve_similar_documents(query)\n",
    "\n",
    "print(\"Top 3 similar documents:\")\n",
    "for doc in similar_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9abd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a75c0637cf416490628e11954d1908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raja\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4950d81fd95f4f0d853b0688b2a6ff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7500f9618662427f9e529974b4fbca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e3ebd398df4344b429ef5ceee8defd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e1dab558b14634a6e0b6f53024e261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Result: [{'label': 'LABEL_0', 'score': 0.2573208808898926}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake_news_classifier = pipeline(\"text-classification\", model=\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "def integrate_for_fake_news_detection(query, similar_documents):\n",
    "    context = \" \".join(similar_documents)  \n",
    "    combined_input = f\"Query: {query} Context: {context}\"\n",
    "\n",
    "    result = fake_news_classifier(combined_input)\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = integrate_for_fake_news_detection(query, similar_docs)\n",
    "print(\"Fake News Detection Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc56b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
